<Blog>

<date>02,August,2004</date>
<post>

	 
       urlLink The Onion | Kerry Unveils One-Point Plan For Better America 
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Trev, You are providing a good example of why the base layer of a data mart should be as detailed as possible  A grain of month, service station, product is a very high level. . Sure, you can add attributes of the service stations but it would be normal for users to ask the 'next level down' questions pretty much as soon as you give them this data.....For example, are there any patterns for which fast food company sells more fuel on the weekend. Which you cannot do with monthly sales figures.  Since it's impossible to usefully divide the lowest level of a grain to it's constituent levels you will have to capture the detailed data and then summarise up to your current levels while also storing the more detailed data somewhere if you are to answer what are bound to be the next round of questions...  It is reasonable to expect your users to ask all sorts of detailed questions including things like sale volumes on particular days, perhaps by weather conditions, public holidays. Then later by other promotions that might even be unrelated to your company. For example if you have fast food vendors they often put on short term specials which might cause small 'spikes' in your sales, and your users might want to know about even them....  So, no, not impossible. Not even difficult if you can get the detailed sales data. So get the data in as much detail as you can and then roll it up...  Best Regards Â  Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com   -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:owner-dwlist@datawarehousing.com] On Behalf Of Trevor Howe Sent: 05 August 2004 08:23 To: dwlist@datawarehousing.com Subject: dwlist: Datamart Design issue  http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to   with the word "help" in the body of the message.  From: "Trevor Howe"       Hi All  I am sitting with a problematic design of one of my datamarts and was wondering if you could inform me of a solution. Here is the scenario:  I have designed a datamart for a petroleum company that reports on gasoline supplied to and gasoline sold from a chain of service stations situated around the country. My datamart has a grain of month, service station and product. My facts are gasoline purchases and gasoline sales. Now the end users want to be able to query according to the facilities offered by the service station. Facilities might be something like: The service station is open 24 hours, the service station has an automated teller machine, the service station has a fast food outlet, etc. They can be in the form of indicators (yes no) or names (e.g. the name of the fast food outlet in the third example above). Unfortunately this does not fit in with my grain of month, service station and product. There is no way to say that the gasoline purchases can be recorded per fast food outlet - fast food outlets do not purchase and sell gasoline. In the three examples above, the users would like to see the volume of gasoline sold for service stations that are open 24 hours, or the volume of gasoline purchased for service stations that have a fast food outlet, or the volume of gasoline sold for service stations with a fast food outlet called  .  Am I attempting the impossible.=20  Your help would be much appreciated=20 Thanks TrevH    
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Greg, I meant ODS is a rather malleable/morphable concept that has been used for a lot different things......and was being used for a lot of things before it got named.....  ONE thing ODS is good for is supporting operational decision making.....  ANOTHER thing ODS is good for is for call center support because it has integrated customer information,   ANOTHER thing ODS is good for is to provide data integration for near real time operational systems as an alternative to EAI which is significantly more expensive....  Obviously it's possible to build it to do just one of these or many of these and more....   ODS is part of CIF for supporting operational decision making. Nowadays if a company is going for EDW and is not considering an ODS I recommend they build one before they build the EDW because they will build one after they build the EDW and it is much more expensive to do it in that order.....In one case of mine we made such a recommendation and the ODS became huge as the EDW withered a bit after a while and no-one really knew how to make proper use of it. (The staff who knew how to use it turned over...)   The modelling technique used.....generally 3NF like a normal transaction based application for the extra performance of updates. However, I see Ralph has published an article a while go discussing 'transaction processing' on a dimensional model... (This link courtesy for Chris Busch) http://www.intelligententerprise.com/020201/503warehouse1_1.jhtml   However, I recently built a large ODS with the Sybase IWS dimensional model as the basis for the ODS.  There are a number of IWS customers using IWS for ODS.   This situation evolved the same way ODSs evolved. Some customers bought IWS and implemented it as an EDW, then decided to build an ODS, and found they could break out the 'current' version of the data from IWS to make the ODS....a complete accident of evolution since IWS was developed as a DW model and it was found, in the real world of using it, it would support ODS processing for all but the most demanding of real time requirements.....As far as I know there is no IWS ODS for a Bank in place yet......because banks now want there ODS to be extremely close to real time...   And yes, pardon the 'soapbox'. I think we should use methodologies more...but customers just don't want to pay for them, so who's going to develop them?    Iterations is the best one available to purchase but so many companies build ODS/EDW with no formal methodology in place...or just as bad, sometimes they do buy the methodology and then won't use it because they want to do the project 'the way other projects are done around here'....   Best Regards Â  Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com  From: "Greg Della-Croce"       So Peter you are saying that since ODS is a very malleable tool, used for a lot of different things, that there is something wrong.   OK, I can buy that if you mean that we could/should standardize the architecture of the ODS some more.   But like RDBMS, that it has grown out of, ODS is just a tool.  Or am I missing the point of if ODS must be CD/Bus or 3NF arch?  Greg   
    
</post>

<date>02,August,2004</date>
<post>

	 
       urlLink :: Flick Your Bank ::   For all those readers in Australia, I found this on the web recently....I think we all pay too much for banking 'services' or lack thereof, so maybe 'flcikyourbank' will prove to be a popular site!!!!  Peter
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Ian,   "I couldn't let this one pass. The idea of reducing redundancy is not to save disk space. If data is redundant, it is possible to produce more than one answer to a question, because data in one location has been updated while in others it has not. Storing a data element in one place eliminates that possibility."  >> Well, we can differ in our opinions...:-)  >> No argument that over the last 15 years or so lots of people have pushed 3NF as reducing the possibility of incorrect answers.  >> But, by introducing 'set theory' into the relational model it became possible to perform many updates of many rows at the same time. (As far as I am aware the relational model was first to do this....it was before my time.)  >> So if data was located on numerous rows it was possible to update that data across those numerous rows with one statement, thereby eliminating the possibility of producing inconsistent answers. And few people in those days were radical enough to propose the same data should be stored on more than one table as we do frequently today.....  >> And yes, I did have to read and learn all things Date/Codd once upon a time. And yes, they say avoiding the update anomaly is one of the 'goals' of 3NF. But that explanation lacks strength in my opinion since the language avoids the 'update anomaly' for you.  >> But if you think of what they were trying to at the time and that was get System-R (as they called it at the time) accepted by IBM and IBM was saying 'too expensive, go away', saving processor and disk sounds like a FAR better reason for 'normalisation' to me.  >> Also, as Ralph dug up and pointed out in the introduction to his first book. In the very early days Date/Codd were not even pushing the relational model as a basis for OLTP, they lost that argument. They were pushing it as a query system for data copied out of operational systems into some separate data store. (No updating...)  >> I was so surprised by this observation I checked around and it seemed to be the case. I found nothing very specific, just far more references to query than to update. Ralph might have seen earlier editions of their work because Metaphor built a relational database into their product and I'm sure the builders of that database would have known much more than me about it...  >> In any case, it's all academic now, 35 years on. Relational databases are widely used for OLTP systems, 3NF is the accepted way of building OLTP systems, and saving disk has gone out the window as a design consideration....   Ian MacGregor Stanford Linear Acclerator Center ian@slac.stanford.edu  Best Regards Â  Peter Nolan   
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Neil,  Sure....   Peter,  I would like it if someone, preferably you since you raised these points, can provide specific examples to the following claims:   > From: "Peter Nolan"   > > > There are some absolutely compelling reasons why this model is a useful > and valuable model, as I have shared here. Especially in the case where > the questions to be posed could not be reasonably known prior to the > design of the DW.  That one I've heard forever. Assumng that the dimensional model and the 3NF model are modeling the same set of data, I just don't see how you can prove this, but I'm willing to change to mind if you can show me.  >> As I've said, it is true that everything that can be expressed in a dimensional model can also be expressed in a 3NF model and both can be made to be time variant.  >> The way this is commonly done in a dimensional model is to make lots of the dimension tables type 2 because type 2 is how history is stored in a dimensional model.  >> So, it follows that if the two models are modelling the SAME SET of data both can support the same answer set. No argument.  "But please, be specific about these limitations of the dimensional model."  >> However, dimensional model performance degrades with increases in the numbers of rows in the dimension tables. With bit mapped indexes the degradation has reduced, but performance degrades none the less.  >> If we take the position that one of the purposes for which we want to design a dimensional model is so that it can be directly queried by the user we would also be wise to take the position that performance is important.  >> So, a designer has a choice in his/her dimensional models. 1. Does he/she attempt to place all the history into type 2 dimensions inside the dimensional model and take the performance hit?  2. Does he/she maintain a limited amount of history based on some form of knowledge of what is valuable?  3. Does he/she do away with most of the history in the dimensional model and go for performance?  And if he/she decides to do away with extensive history in the dimensional model, where should it be put? Or should it be discarded?  My point is only that an archival data store allows you to archive data in a place where query performance is not an issue so that you can achieve greater performance from the dimensional models that people are interacting with directly.  Further, because this data is archived away in such a way that you can understand it and get to it in a reasonable amount of time you know that if you need it in future you CAN get to it.  And my real world examples are archiving lots of attributes of customers and account or policies or whatever financial instrument you care to mention.  To archive these attributes inside type 2 dimensions and connect those type 2 dimensions to your fact tables and then run queries that touch those large dimensions will run more slowly than if you did not store that kind of history in those large dimensions. There's not argument with that because over the space of 5 years it would not be unusual to have an average 15-20 or more changes to account/customer information.  And so, often times, people have built archival data stores, in a variety of fashions, one being 3NF+TV+SA, in order to be a place where designers and developers can go to fetch archived data that has now become 'needed' for whatever reason.  >> So Neil, specifically, clearly, unmistakably, if I have 10M rows in a customer dimension table and join it to a fact table, and if I have 150-200M rows of the same 10M customers with all their changes over 4-5 years joined with the same fact table and I ask a question at the detail level the join using the 150-200M row dimension table will run more slowly because more rows keys will be returned from the larger dimension table. Is this specific enough?  > > Dimensional models have some limitations on them and recording every > value of every field in every operational system that stands a chance of > being valuable in the future and still be fast/easy to query and > understand is one of those limitations. > "Who in their right mind would do such a thing? This is a rhetorical answer to divert the discussion from the real issue. Most of the data in operational systems is jumk as far as BI is concerned. Lets stick to to what's relevant. In fact, the designer doesn't know, for sure, what data is important at the beginning, a limitation of both approaches. Over time, they are both cumbersome and expensive to maintain because the models change. But please, be specific about these limitations of the dimensional model."  >> Please note the 'and still be fast/easy to query'....  >> Absolutely, most data in most operational systems is not needed in what has become our idea of BI. BI has become this idea of some relatively well defined set of data answering some relatively well defined set of questions. And the BEST model to do that with is the dimensional model. (relational or otherwise.)  And we get these systems with nice charts and nice dials and a web interface and lots and lots of people have access to this BI thing, but are we really making a big difference in the company? ..Maybe, maybe not.  >> My experience is that there are questions that arise from time to time, the answers to which may sway very large decisions and very large value to the organisation. These are questions which no-one could have reasonably known at the time of constructing the DW.  You want a real example. I'll give you a real example.  A legislation change in Australia with respect to tax treatment of retirement funds caused a lot of confusion. My client, having ALL DATA IN ALL OPERATIONAL SYSTEMs IN THE DW (though not time variant at the time) was able to make a detailed assessment of the opportunity/threat.  They prepared a request for the biggest single marketing exercise the 100 year old company had ever undertaken, presented it to the board and got the approval. Hundreds and hundreds of people were involved in this campaign. The result was the company gained $A440M in funds under management which is $A4M profit per annum. The company went from NOT BEING PRESENT IN THE MARKET SEGMENT TO BEING THE LEADER IN THE SPACE OF 6 MONTHS.  And this was only the second biggest single decision payback they got out of their DW. The largest decision was worth in excess of $A10M per annum in profit. No, I can't discuss it.  The legislation change could not have been reasonably predicted at build time.  >> Now, yes, in such a situation one can argue that it is possible to build all that history into dimensional models and this is true. But if they are the same dimensional models people are using every day in their normal run of the business such a solution introduces a slow down if implemented as type 2 dimensions.  >> And as the person who designed that database (as bad as it was at the time) I can say my opinion is there is no way I could have built a dimensional model that would have provided reasonable performance and yet have answered such a complex question as 'what should we do about this legislation change'....I wish I was that smart, but I'm not.  >> And apparently the person in his 'right mind' was the rather visionary director of marketing who funded the project.  >> He held the absolutely firm conviction that there was value in the data obtained by the company in it's course of business and he wanted to get at that value. He launched the first round of the project and was a supporter until he left the company.   > > What you are saying is that 'all detailed data should be queried'. > > Who says all data should be queried? Some data may never be queried.  No, that isn't what I meant to say, but that's the way it came out.. What I meant to say was that any data that is published in summary form should have its underlying detail also available.  >> I couldn't resist it...;-) All those logic classes. They have to be useful for something (LOL).  >> Yes the detailed data should be around somewhere.....  Even the word "normal" was a joke. Codd said, "Nixon was normalizing relations with China, so that's what I called it, normalizing relations."  >> It was so long ago, who knows what was in their heads at the time.  > > (Or at least, in 4 years of thinking and trying I was unable to get a > dimensional model to support both query requirements and archive > requirements. And a number of the 'best and brightest' put their minds > to this very problem archive data in a dimensional model because we knew > the dimensional model had to stay. We failed. Simple as that. Which is > why the archive layer has become a widely used implementation. > > Why muddy up a data warehouse with archiving data you don't know if you need? Back the stuff up, why waste money integrating it?  >>> Because there are these classes of questions that you know will come up and they will make a huge difference to the company if you can get it right and react faster than your competitors. We do it for the best reason of all in a company...profitability.  Just backing it up will not get you anywhere when you need it because when you need it you will not know what it means, how it integrates to other data, or how to use it.  I like the library analogy. Just backing it up is like building a library where every book published is just put in the next available space. Building an archive is like taking a look at the abstract, think about where it should go, put it in it's place, and put index cards in place referring to where it is just in case you ever need that book in the future.  And I would hope that it is self evident that libraries are a valuable resource, even though we so rarely visit them ourselves nowadays!!! An archive is like a library of all the data you ever came across that you thought might be useful one day.  And yes, it takes a visionary to say. 'There is huge value in the data in my company, make money out it.' Unfortunately, IT people hear such things and think it's a blank check to build whatever they like. They don't link it to profit contribution of the company....   Examples please.  >> One more....  I designed a BI Environment for a large mutual insurance company. It was sponsored by the 'Director of Customer Vision Projects'. We spent a year selling the company on the concept that there was value in their data and we knew how to unleash it.  The FIRST question asked came from the gods above..  "We are considering de-mutualising, tell us what the liability is for your region should we do so."  That's decision support.  How would I have been able to design the 'demutualization' model?  Of course, after I had been asked that question I could design the model, populate it and answer it. (Any fool can do that.) But by that time it is already 'too late'. What used to take much more skill was to archive just the right data that is likely to support such unknown questions....of course, we will soon be heading into the era that we can afford to keep ALL THE DATA ALL THE TIME.......then the skill will be actually getting the value out of it....  Our client was able to answer within the week. The only region in the world to be able to do so.  The customer was so pleased he asked us if he could speak at a conference we were involved in....where he said something like:  "Our company has managed to make millions and millions of dollars of profit from our investment in our Customer Vision Projects with XYZ vendor, I strongly recommend you do the same."   >> Enough examples above or do you want more???   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> >   So Neil, I don't need to justify the value of an archival data store to you or anyone else on this list. I justify the value of these things to my clients.  My experience, and the experience of many others, over many years, has shown us that there are a class of questions that, if answered effectively, can make millions and millions of dollars of profit for large companies.  Our experience has also been that the value of this class of question often outweights the normal 'run of the mill' questions like 'how many widgets have I sold this month'.  How this is actually achieved, the business couldn't care less. We could be doing it on slide rules for all they care.  I know that having an archive of a broad range of data (if not all the data) across an organisation and great tools to query it with will provide a rich repository of information for an organisation to stand a far better chance to answer these questions as they come up or are posed by smart analysts.  Whether you or anyone else on this list agrees with me is not relevant to me. I'm simply sharing a little experience and knowledge.  And Neil, given that all this conversation stared over the comment that IWS achieves the ability to put the archive into the dimensional model that end users query, of course a dimensional model can do all that I have described as being in the archive....that's were we started.....;-)..The IWS model is provable and being logically equivalent to a non-lossy archive yet suffers no performance degradation because it achieves this astonishing result without having to resort to type 2 dimensions.  It is just that IWS has specific proprietary features to enable it to do so.  Best Regards  Peter    
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Chen, I know of no other way to have people lose faith in a delivered DW faster than having the DW/DMs present differences of opinion about what a number should be.  Time and time again I have been asked to discuss with companies what to do with their array of 'independent, semi-dependent, interdependent data marts' because the answers coming from each of them were slightly different.  In nearly every case, senior managers refused to use the information at all if there was even the slightest hint that it was not consistent. This is strange because they will use highly inaccurate information just as long as every data mart gives the same wrong information.  My answer, over years of experience came down to, if you have 4 or more, throw then away and start again. I was thrown out of plenty of places for proposing that course of action by the way.  The timing differences that will occur between operational systems and the data marts you are proposing will be more than enough to cause differences that may well undermine your efforts.....I'd always suggest that 'drill through' be 'drill through' to a detailed level that is synchronised with the data marts.....whether it be a so called EDW or just more detailed dimensional data. By all means drill through to operational systems if need be, but provide some kind of 'disconnect' between the data marts and the operational systems so that differences in the numbers are far less likely to be brought up as a concern....    From: "Chen, May"            Some of our designers/architects have the concept that detailed information must come from an operational database (ER model, a replicated transaction database) while analytics will be using data marts (Dimensional model). During an analytics session, we drill down to some level of detail and then the user will see a more detailed page that is sourced from operational database.  Here are some common sense issues: The data from the 2 databases are on different frequencies - one is real time and the other is daily snapshot. The users may see inconsistent data. For example, on one report, I have 2 orders and next report shows that I have 3.  The data from operational database are raw and the data on data mart are transformed. For example, on one report my 2 order status are shown as unknown and the next report of my 3 order status are shown as 1, 7 and 9 (both 7 and 9 are transformed to unknown).  From a business point of view, the above reports are not acceptable. Any industry experiences on solving these types of problems? Why must the detailed information come from an operational database? Should all the reports source from data mart? Why and why not?  Thanks in advance  May Chen =20      
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Jim,  "I too recognize the value of leaving room in methodologies for innovation, but I must point out that leaving out so much fundamental information about the ODS has done the field - in my experience - significant harm. Specifically:  In practice, "ODS" appears (again, in my unscientific survey) to be an undefined architectural entity. Some clients have built "ODSs" for operational reporting. Some for the maintenance of "master data" (dimension authorities). Some for the ETL process itself. Some retain full history there, others don't. You name it - we've all seen it: simple staging areas, integrated & non-integrated, 30 days history, 5 years history, reporting, cleansing, subject aligned, departmentally aligned, normalized, semi-normalized. Never dimensional though - this is a new one. And many hybrids of the above. Unfortunately, I have yet to see one that I thought was optimally engineered for whatever its specific tasks were. The ODS, too often in practice, appears close to chaotic. It has become a convenient container for whatever functionality has been left out of the other CIF components.  And this, I submit, is a pity."  --Jim Stagnitto   Actually, I agree that we would all be better off if we had more solid architectures to work off. Perhaps some of us might even use them...;-)  But who is going to create these? And who benefits from these? IT people want someone to go out and create such things for free and then to give them away for free as well......eg. How many people on this list have participated in a DW project with no formal methodology in place to guide them along the build??  Also, methodologies often tend to become a replacement for 'thinking'. Example, Method 1 at Anderson Consulting. The concept being that you could hand Method 1 to someone with 2-5 years experience and they would be able to build anything because the methodology was so good.....  Where is the middle ground? I believe designers of IT systems should get reasonable training and apply the grey matter to the problem at hand....and today we have the best facilities ever available to support designers of systems, yet I see the same mistakes Frederick Brooks described from 1965...amazing...   Vendors...  At the end of the day, the vendors need to make profit. The best way to make a good margin is by 'differentiation'. 'Being Different'.  A vendor selling commodities is taking a very dangerous path.  Vendors don't want 'standards and agreements' on how things should be done so that customers can turn their products into commodities and drive down their prices.  This is why we have no 'standard' unix, no standard C, no standard C++ and why we will have no standard Java in the future. Remember all the hype around 'unix and C' will become the standard and replace the mainframe.  The vendors are motivated to produce 'tweak' their products to 'look different' and the space of ODS, DW, BI etc is not immune to this 'tweaking'.  If you talk to IBM, NCR, Oracle and Microsoft you will see how little similarity they have in what they say the BI world should look like. For a start, each of them says their products are the be all end all and should be at the center of everything...;-)  Just as an aside about definitions of ODSs. PwC also decided to give the ODS their own definition as the archival/integration layer with no near real time object in the picture.....now try explaining that one to a bunch of big companies...  Best Regards Â  Peter Nolan   
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Clare, Well put. I also feel that there and been an epidemic of 'we forgot why we are building a DW'. So many are built nowadays to perform 'operational reporting' in order to try DWing out......and when you spend money building a DW for operational reporting it's not hard to wonder why we didn't just make it all one big system...  But the days of selling single integrated models with all functions built on top of it are over...we (IBM) tried that in the 80s and lost.  Packages will be here forever. And occasionally companies will change packages for various areas....this dramatic disconnection of the design of the source data between packages and between changes of packages is going to keep the DW separate for a long time....  But let us not all forget the original defined purpose of a DW...support the management decision making process......and I keep saying here and everywhere else, the number of managers is very small....not everyone needs a USD1000 analytical tool on their desktop...  Best Regards Â  Peter Nolan   -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:owner-dwlist@datawarehousing.com] On Behalf Of Claire McFarlen Sent: 20 July 2004 03:02 To: dwlist@datawarehousing.com Subject: Re: dwlist: Stick figures and Moore's Law  http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to  with the word "help" in the body of the message.  From: "Claire McFarlen"       I see nothing artificial about separating the data warehouse from operational systems.  Ten reasons for keeping them separate (with apologies to Kimball, who I think has already stated many of them in his books):  1. They have different functions and different objectives. 2. Good design recognizes that form follows function (e.g. why we don't see too many Formula 1 racing cars hauling garbage, or tractor-trailers entered in the Indy 500) 3. DW queries generally search and process large sets of data, while operational systems process individual records one at a time, mostly Adds and Changes, some Deletes. Operational databases are tuned to optimize the most frequent access paths for a finite set of pre-defined database calls. DW needs a different tuning strategy to manage an infinite, unknown set of database calls. 4. DW is read-only (with some possible minor exceptions like derived risk rating) while operational systems are heavy-duty transaction update processors. 5. DW tends to be more forgiving in terms of response times and 24X7 access, while operational systems demand 2-4 second response times and continual access 6. The DW service level agreement is usually not the same as for operational systems - DW can probably be offline longer than core operational systems in the event of a system failure or disaster recovery. 7. DW strives to be, and is most useful as, an enterprise-wide endeavor, while operational systems break down business functions into well-defined and manageable divisions of work 8. Many DW queries need to be run in a relatively static environment. If transactions are constantly being added and changed while a long-running query is churning through data, there are going to be anomalies and contention issues. 9. Operational systems carry tons of process-only fields that are not needed for DW queries - forcing DW queries to churn that data is wasted energy. 10. Change management for one system should not impact other systems.  Re #10: With well-designed OLTPs, if one core operating system runs into trouble, other core systems are relatively protected, at least for a period of time until system-to-system interfaces are involved, and a good OLTP builds in workarounds to deal with the possibility that another dependent system may be temporarily out of service. If you are going to bind the DW with transactional systems, then you are binding together all the transactional systems as well.  It's a bit ambitious for IT to attempt to guarantee that all systems including DW will be available at all times no matter what. It's difficult enough to guarantee this for a single core operational system.  As we now know from Neil's survey, users aren't exactly thrilled with DW and don't see it as being fundamental to getting the job done. Oddly enough, I'm inclined to agree with that view. Core operational systems are the critical path; DW is nice to have. Short term needs have to be met first, before long term goals (i.e. having a robust DW) can be resourced.  Businesses got along pretty well before DW came along. They got along pretty well before computers came along. The one prime directive for business is, and always was, to do business. Sell the stock or the service and get your money, otherwise there isn't much hope of succeeding, whether you have no competitors or a million of them. Marketing is great stuff, but a business lives and dies by its ability to conduct business transactions. Its nice to know how many customers in a particular demographic bought Product X when the price point moved down two points as opposed to the previous month when it didn't, but first you have to sell those Product Xs.  To say that DW is "the future" is a somewhat facetious argument. The future tends to look a lot like the past. Reliable, robust and easy-to-change operational systems are the future and anything that could jeopardize those systems is not the future for a company that wants to stay in business. Intertwining DW with all core operational systems would introduce a huge component of risk: and successful businesses are built on recognizing where risks lie and how to avoid them, only entering into managed risk situations under controlled conditions, and only if there's a very compelling reason to take that risk. To a business sponsor, trying to convince them to integrate all their core operational systems, plus the DW, into one big giant glob would probably make as much sense as telling the Mayor of LA that from now on, all the freeways and all the parking lots are going to be mushed together. Why? Because it seemed artificial to keep them separate...  What empirical evidence is there to support the notion that DW and transactional systems would be better off co-habiting the same environment? What evidence is there to even suggest this would be a buildable system, a manageable system, a useable system? Everything I've seen in IT tells me that discrete systems that are focussed on identifiable business functions are more successful over time than large, all-encompassing systems because a focussed system can be adapted faster to respond to changing business requirements.  I like data warehousing and dimensional bus architecture in particular, but I'm not oblivious to its purpose, scope, limitations and role within the business. Maybe one day we will see one giant computer system that can "do it all" but I don't much like that notion, it sounds pretty Orwellian. And I sure wouldn't want to be stuck with supporting a monolith like that.   Claire McFarlen Data Warehouse Consultant Clay New Media       
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Robert/All,  I have copied what you wrote below (at the bottom) for anyone who missed itâ¦â¦  Firstly, thank you for the appendâ¦.I have been telling people something very close to what you describe is something that is very difficult to do in dimensional modelling but only the senior managers take any notice. The IT folks donât get the problem Iâll mention laterâ¦.  However, the problem you describe is actually trivial to solve with an archive layer and type 2 dimensions. (I donât have bills 3rd edition so I canât refer to what exactly he wroteâ¦..but letâs not forget Bill has not been a designer of any significant number of dimensional models that I am aware of. I know he has reviewed many. For example I know he has reviewed Sybase IWS and one of his companies has decided to use it. I also know he has signed a non-disclosure agreement regarding IWS. So, it is safe to say Bill is fully aware of the leading edge modelling dimensional modelling techniques used by IWS, he just canât write about them, and neither can I!!!)  (http://www.sybase.com/detail/1,6904,1025065,00.html )  Back to your questionâ¦.  An archival layer, (ala Bill Inmon) can be developed on the basis of being non-lossy if one likes. Non-lossy meaning that no data and no meaning is lost in the process of moving data from an operational system to a data warehouse. Few people do this because there is some data in an operational system that is just never going to be useful to any possible question that might be of value to the business.  The process is relatively simpleâ¦.for every field coming into the DW it is inspected to see if it has changed from itâs previous value, if it has changed a new version of the field is recorded. If something changes every day there is 365 copies of it at the end of the year. Like account balance on my credit card!!!! If something changes only once a year, like my age, then there would be only one record per year stored away. This is time variant data. Itâs in Bills books and you can read about it on my web site here (http://pws.prserv.net/ieinet.pnolan/downloads/Newsl2.zip ).  Having stored all data as it was at the time it was extracted and only discarding data that the designer believes will never be used solves the first part of your problem. That is the DW should be able to accurately re-create history. Only, by definition, in this case we are not re-creating history, we are storing history as it occurs and we are not changing it. Hence the time variant DW archive layer, by definition, can provide you with the sales reports for how the business looked at the point in time.  But, and Bill has said this many times, it is not possible to query the archive layer in any meaningful way. The relationships are too complicated and the performance is too bad. You need tons and tons of computing power to query such a model. (One reason why NCR are so fond of pushing his ideas and discrediting Ralph.) Dimensional models are more efficient, not good for an MPP vendorâ¦  So, if you canât actually create your sales report from the archive layer where can you create it from? Prior to Ralphs first book, Bill recommended exactly what I had come up with in 1991â¦some form of flat table structure that is programmatically extracted from the archive and placed into a summary table on a regular basis. In those days it was monthly. So, each month we could pull out an image of âsales this monthâ and store them in a single flat table with a date field at the front which was the first (or last) day of the month. Clearly this meets your need for presenting the sales of an organisation as they were in the organisation at that time.  In 1993 I was trained on star schema design by Metaphor as well as meeting Bill at a seminar. It was about 2 years later that another guy and I came up with the idea of replacing these time sliced summary tables with start schemas for analytical processing. Thus, in 1995 this colleague and I started selling the concept of doing both, archive layer and star schemas. This concept has been widely accepted as delivering the most comprehensive data infrastructure possible because you have an archive layer which is ânon-lossyâ for all practical purposes AND a high performance analytical layer. Just recently Earnst and Young did a report for a client that had about a million and one references for this being the âindustry standardâ architecture and the client gave me a really hard time over IWS as these âso called expertsâ KNEW a dimensional model could not store an archive layer despite never having seen IWS.  When we built both archive and analytical layers we simply replaced bills idea of a summary table with a multi-level summary fact table. And this is important to note. The star schema was functionally equivalent to what Bill had been promoting it was just easier to maintain. There was absolutely NO FUNCTIONAL IMPROVEMENT at that time we first started putting star schemas into the overall DW architecture. We used some âcheatsâ like having the detail level fact tables âmorphâ between the archive layer and analytical layer. We also âmorphedâ detailed level dimension tables between the two layers. It was a brilliant cheat that won me many, many dealsâ¦. ;-) I can talk about it now because itâs redundant and has no value versus Sybase IWSâ¦.;-)  So Robert, your question. How does this work in the archive layer?  The customer became a customer on December 15th 2003. So the customer record might look something like this.  Generated Key 987654 Customer num 12345 Date from 15/12/2003 Date to 31/12/9999 Current flag 1 Name ABC Enterprises Etcâ¦.   The customer buys 100 units in January. Each individual transaction is recorded with generated key 987654 on it or customer num 12345 on it depending on what the designer chooses to do. The summary sales record for January 2004 looks like this.  Customer num 123435 Name ABC Enterprises Month Jan 2004 Sales 100  There is no need to describe the transactions (I would hope.)   The customer changes his name on the 15th of February to XYZ enterprises. He buys 50 units in the first part of the month and 60 units in the second half of the month.  The customer records will look like this. Generated Key 987654 Customer num 12345 Date from 15/12/2003 Date to 14/1/2004 Current flag 0 Name ABC Enterprises Etcâ¦.   Generated Key 9876541232134 (whatever) Customer num 12345 Date from 15/1/2004 Date to 31/12/9999 Current flag 1 Name XYZ Enterprises Etcâ¦.   The summary sales records will look like this:  Customer num 123435 Name ABC Enterprises Month Feb 2004 Sales 50  Customer num 123435 Name XYZ Enterprises Month Feb 2004 Sales 60   Now, these sales records can be in flat tables, they can be in star schemas, you could write them on paper for all I careâ¦.;-) But they do show the sales figures as they were at the time and they reflect history accurately.  So, where is the problem you have that says this is mathematically impossible? Iâve done this plenty of timesâ¦.it worksâ¦.itâs simple, in fact itâs trivial.    Now. Robert.  Lets talk about something MUCH MORE DIFFICULT, just because itâs Friday night and I feel like spending 30 minutes showing offâ¦ ;-)â¦and hopefully someone out there who reads this append will give me a contract one dayâ¦ ;-)  Recording history and being able to re-present it at any point in the future is NOT ENOUGH for even the most feeble minded Directory of Marketing. It never has been.  What the director of marketing, CFO and CEO want to know it this. (And I have had plenty of them ask this question, so this is as real as it gets and since it is almost always the highest level management asking and they are trying to track the impact of multi-million dollar decisions, itâs also important. Just check out ârestructure chargesâ on balance sheets of major companies and you will see how important.)  CEO: âI restructured the company on January 1. Tell me. How are my sales going this year vs last year?â  An innocuous enough question but there is a bomb in there. This years sales structure is not the same as last years sales structure. Comparing the sales for these two structures is irrelevant at best and misleading at worst. After all, last years sales were NOT SOLD USING THIS YEARS SALES STRUCTURE.   Letâs see what I meanâ¦  In 2002 Region 1 has divisions 1,2,3 which sell 120, 240, 360 units for the year at 10,20,30 units a month. (just to make the numbers easy)  Region 2 has divisions 4,5,6 which sell 480,600,720 units for the year at 40,50,60 units per month.  We restructure and we split division 6 into two and call it 6a and 6b. We move 6b into region 1. We fire half of Division 1 because they sold so little and we move the remainder into division 2 to bolster it up. And of course we transfer some of the successful reps from division 2 and 3 to division 4, after all âthey done goodâ we should let them fly with the eagles because the turkeys in division 2,3 will drag them down if we leave them there for too longâ¦.and a few of the dud reps in divisions 4,5 we had better spread around divisions 2 and 3 to make up the numbers thereâ¦.after all, since they are dud reps they are probably on their way out anywayâ¦. And we had better move some of the more important accounts from divisions 2 and 3 and put them into division 4 to bolster it up a bitâ¦.and letâs make something of a competition between divisions 4 and 5 to see who can sell the most this year, that will get them sellingâ¦.So we need to start them off on what their people believe is a âlevel playing fieldâ.    Great, weâve finished playing musical chairs with our reps and our account assignmentsâ¦So now we have:  Region 1 has divisions 2,3,6b and region 2 has divisions 4,5,6a. with different people, some moved accounts, some new products and services of course, and some old ones have been droppedâ¦.  And the CEO/Director of Marketing still wants to see. How are we going this year vs last year?  This means I have 2 specific casesâ¦.  1. I must report last years sales and this years sales using last years reporting structure. 2. I must report last years sales and this years sales using this years reporting structure.  The more general case which is the one that I prefer to solve is to report any periods sales vs any other periods sales using a reporting structure at ANY point in time.   THE ONLY WAY Iâve I was ever able to solve this problem (before IWS) was to use an archive layer and to record the most detailed data I possibly can in the archive layer. Then when the structure changes I build relationship tables between the detailed level data in the old structure to the detailed level of the new structure. Note that if the lowest level of detail splits it is NOT POSSIBLE to split the numbers 100% accurately. You must split them based on some estimate or otherâ¦â¦  So, having built the relationships between the old and the new structures, and having built them in a time variant structure as well because the CEO is going to change his mind and move people/divisions/products/customer accounts during the year you can bet on it, I can safely say that from this structure which records the way things look at any point in time as well as the relationships between these things over time I can produce any report that the CEO might ask forâ¦  Only problem is I need too much money to run the reportâ¦â¦so to get the efficiency of running the report I must use a dimensional modelâ¦..but a type 2 dimension only records the way things looked at the point in time they happened. A type 2 does nothing for me in this case. I cannot do items 1 or 2 with a type 2 dimensionâ¦â¦.And in a type 2 dimension I have no relationships recording the relationships between the changes in the sales structures. Those who think this can be done with a single type 2 dimension are dreamingâ¦..that IS mathematically impossibleâ¦;-)  And since I have something called a region dimension and I have something called a division in the region dimension I am pretty much screwed with a dimensional model, or am I?  If you have been reading along you will notice that I said I try to keep things at the lowest level of detail in the archive layer. So, I must be able to create a snapshot of the organisational reporting structure at ANY point in time, and I must be able to relate that to any other organisational structure at any other point in timeâ¦.after all I have all the relationships I needâ¦..  But I canât afford to make multiple copies of facts tables and run multiple attributions processes to put keys onto the fact tablesâ¦â¦..what can I doâ¦.well, I CAN afford to build multiple dimension tablesâ¦and if I am real careful with my keys I can make my keys the same for the most detailed level data for each version of the dimension table. And then, I can connect each version of the dimension table to the fact tables using the detail generated keys and whola I can report last years sales by any version of the dimension table I care to build and I can also build this years sales based on any version of the dimension table I care too buildâ¦  And if I build a version of the reporting dimension table each month I can in fact report sales for any period by the reporting structure at month end.  For those who have read a lot of Ralphs stuff you will recognise this is a type of âHot Swappableâ dimension except you donât âswapâ them. You just build them and you set a current flag on the latest version so that the default for reporting is to report sales over the extended period by the current reporting structure which is what people actually wantâ¦.Note, what people DO NOT actually want is to report sales by the structure that was in place at the time of the sales which is what a type 2 dimension gives you if you do nothing elseâ¦â¦. The only folks who want that are the folks who have not thought about their sales analyse reporting in enough detail yetâ¦  Any I have seen plenty of customers who build these lovely cubes in the cube products and are always reporting what the sales looked like at the point in time and they are floored when the CEO says âbut I want last years sales by this years reporting structureââ¦..and if they beaver away and get that right they are even more floored when the CEO says, âI wonder if we would have been better off if we had not restructured, show me this years sales using last years reporting structureââ¦â¦I am sure that the older DW consultants out there would vouch for having seen these very questions time and time again.  Anywayâ¦â¦I thought I was pretty clever figuring all that out by myself until I ran into Sybase IWSâ¦.and my first IWS implementationâ¦â¦  The customer was a debt collector and this is what he asked for as near as I can remember itâ¦â¦..  We have 400,000 debt collection cases live at a given point in timeâ¦..we have 300 case officers. Those numbers are growing rapidly. Cases can take years to resolve. Cases can be passed between case officers at the manages discretion. Cases can be passed between departments with agreements between the departments. And cases can be reallocated across departments at the directors discretion.  We want to know: 1. Whether some of the case officers are managing their cases in such a way as to reduce the probability of being successful in the case. 2. Whether some of the case officers are managing their cases in such as way as to increase the probability of being successful in the case.   You need to keep in mind: 1. Case are not the same. There are many types of cases and they cannot be compared across types. 2. Cases move between cases officers on a regular basis so you need to be able to vary the length of time a case of a certain type is held by a case officer before comparing it with other cases to see if the close probability has increased/decreased compared to the norm. 3. That a good case officer can lift the close probability of a case managed by a less successful case officer and vice versa and you need to take that into account as you calculate the relative performance of the case officers. 4. Case officers often get cases closed by lowering the amount they will accept to close out the case so you are to measure profitability not closure rates. 5. Since we want the numbers to be âirrefutableâ you will need to balance the profit calculated across the 400,000 cases to the ledger on a monthly basis.   When we find that out the above we want to know what the different case officers do differently. We want a way to alter the business processes of the less successful case officers to make them more successful and we want to be able to measure the improvement across the cases which are managed differently. However, we want to be able to incrementally introduce new and innovated ways of managing cases and compare them against other successful case officers during the testing period who are not using the new techniques to make sure that we are succeeding in the changed business practices before we roll them out across the company. We need the concept of the control group so we do not mistake changes in the general environment for success of what we are doingâ¦..  Customer: Nowâ¦show me how you do that in IWS..  Peter: Hmmm. Iâll have to think about thatâ¦â¦  Customer: Well, how have you done this before????  Peter: I went into the whole long explanation of the aboveâ¦.  Customer: I donât like that much. It looks too complicated for me. And it does not allow moving cases during the month which happens. Whatever you do, it must be at a daily level.  Peter: Hmmm. Iâll have to think about thatâ¦â¦   So, Robert, the punch lineâ¦â¦itâs taken a whileâ¦.but I hope it was entertaining â¦..;-)  I go into the IWS model and start to really look at it very, very hard to see how it could possibly do what the customer is asking for, or, how I could change it, or how I could write ETL to do itâ¦â¦.what did you think I found?  IWS does all this and more with NO multiple versions of hot swappable dimensions at a daily level (or at a second level if you wantâ¦.because itâs a timestamp). There is no redundant data storedâ¦..there is no need to store the relationships between the âoldâ reporting structure and the new reporting structureâ¦there is no need for an archive layer, all of this is housed inside a dimensional model and all the data is visible to any query tool you would like to buy.  I was amazed and very impressed. The problem had been solved more elegantly than I had ever seen in any other model of any other kind.  I called the guy who designed it and told him how impressed I was and how much he had gone up in my esteemâ¦â¦.he was pleased and we are firm friendsâ¦.;-)   And my last point.  For all those who like to line up to take swipes at what Bill has publishedâ¦..  I know that Bill has seen how IWS performs this rather miraculous piece of wizardry. I would guess he has had time to digest it and understand it by now. So his knowledge of how star schemas can be made to work is excellent. (It might not have been when he wrote his 3rd edition, I donât know.) IWS (in fact) stores the archive layer inside the star schema and is capable of doing so in a non-lossy format over significant periods of time and Bill is aware of this. He just canât write about itâ¦  As for the claim on this board that should someone publish something they had better be prepared to defend it. Nonsenseâ¦.Itâs a free world and people can publish pretty much what they like within certain lawsâ¦..itâs the readers choice to use or not use what is published. If someone does not agree with something that is published and wants to take up some argument with the author then the author is free to ignore the argument. Argument takes time and costs money.  Example: I am reminded of when I attended Bills seminar in Sydney in late 1994 (Standing room only by the way).  There was a âproblem childâ in the audience. Call him Bruce (good Australian name). Bruce was of the belief there was no need to copy data from operational systems and build a data warehouse. You could build a âvirtual data warehouseâ and do all your decoding and integration on the fly according to Bruce. (Why he was even nthere is a mystery to meâ¦)  And every question he asked he was challenging Bill on the very fundamental point of âwhy copy the data in the first place?â And he ended each question with, âI wouldnât do it that way (meaning the way Bill was explaining) if I was building a data warehouse.â  Bill was ever so polite, despite the fact that young Bruce was taking up the time that 100 other people were paying good money for. (I would have thrown him out and given his money back.) After about the 5th or 6th time young Bruce did this Bill chose not to answer the question. When young Bruce said âI wouldnât do it your way if I was building a data warehouseâ  Bill replied: âYou are right Bruce, you probably wouldnât.â  And that just about sums up Bills message. He presents some ideas in books papers and what not. The best he can come up with, the best he can write them and he publishes them. Itâs hard work, and itâs not very good money either. Some people have taken some of his ideas on board and built highly successful data warehouses using these ideasâ¦me included. And there are plenty of others I know who have successfully delivered tremendous business value using many of Bills ideas.  If any-one who is reading this doesnât like what heâs written, I invite you to join young Bruce, do it the way you think it should be done.  (And see if you can get 100 people from the biggest companies in Australia to pay good money to listen to you talk about how you would build a data warehouseâ¦. ;-) )  For those who got this farâ¦I hope the append was entertaining, if nothing elseâ¦ âº  Best Regards  Peter Nolan www.peternolan.com  >Here's my point: > 1) It is a requirement that all data warehouses be able, >architecturally, to accurately recreate history. Sales reports for >2003 that breakout sub-totals by customer shouldn't change overnight in >2004 because a customer changes their name or merges with another >customer in 2004. Yes, of course, a purchaser of data warehousing >consulting services may not want the ability to recreate history across >all angles of analysis. But the point is the data warehouse should be >able to easily and gracefully accomodate the requirement if it should come up. > 2) If you are not going to use the concept of a Type II dimension to >achieve point #1 (or one of its cousins), then what exactly are you supposed >to use? Fancy charts with stick men figures, text in clouds, endless >lists of bullet points to consider, fancy language such as time >variant, 3NF, archival layer..., don't get you any where when it comes >time to actually create an Oracle table and an associated Informatica >mapping, and deliver a product. > 3) After researching and experimenting for months using the Bill Inmon >approach of using a 3NF database enterprise data warehouse to populate >a star schema, I am convinced that it is literally mathematically impossible >using this approach to achieve point #1. The rules of relational >algebra don't support it. Furthermore, nobody but nobody has ever laid >out in concrete terms (e.g., here's AN ACTUAL EXAMPLE) of how to do it, >and the includes, from what I can tell, all the slaughtered trees >associated with Bill Inmon -- sure I could have missed it and no, I >haven't read everything of Bill Inmon's, but how tough could it be if >it is such a well documented, real world tested methodology? Can't >sombody take literally five *#$@!~!@ minutes and sketch out a 3NF >database that preserves history and then feeds a star schema and post >it on this listserv?   Best Regards  Peter Nolan   
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi All, It is interesting to see the discussion around 'real-time data warehousing'...  One of the definitions (offered buy Inmon, Imhoff, Battas) is as follows:  "The operational data store, or ODS, is a dynamic architectural construct designed specifically for high-speed, integrated operational processing. It achieves at the operational level what the data warehouse does at the strategic/managerial level."  So, a Information Architecture (someone doing ODS/DW and BI, we have too many acronyms) might consider that when the problem at hand is an operational issue, which must be addressed in the near term, and does not require a 'meeting of the minds' to discuss and set strategy to decide where large investments might be made, then some style of operational, integrated, information might be the better answer than try to make the DW 'fit' the operational needs.  Please remember, the reason the ODS developed was exactly because people started using the DW for operational processing and the technology of the day was unable to cope with the varying processing loads of OLTP and DW style queries. Further, as we evolved to archive/analytical layers and the increased use of dimensional models the processing requirements to get the data into a dimensional model further aggravated the cause of keeping everything 100% up to date all the time.  To the best of my knowledge, we are still at the stage where large organisations cannot reasonably expect to integrate operational processing with DW processing on the technology that exists today. Plenty of vendors will tell you that the 'next release' will do this....IT people buy the 'next release' at their own peril.  Sure, we will see this distinction/separation between OLTP in the ODS and the DSS in the DW blur over the coming 5 years.....  But I am not aware of any absolutely compelling reasons to combine them today given that the data can be made to flow between ODS/DW relatively quickly without forcing it all into the one model...  If you look at examples provided for real-time decision making, they are minor and relatively un-important in the over-all schema of a large company. Most such decisions can be made just as well reporting driven from the operational system, or an ODS, or perhaps even with just a little common sense.  I recall a story recently (by a vendor) where the example was the 'real time' DW could assess that a customer had a poor interaction with the company and he/she could be called back and somehow placated.  And my response to that was that customer facing people should be trained to take reasonable care of customers so you don't need to spend millions of dollars catching the failures of the customer facing staff.....what a radical concept, good customer care..;-)   Just an opionion....;-)   From: "Greg Della-Croce"       Gabriel, Thanks for the input. The example you used is great. It falls into what I call the "Operational Information" for a client (as opposed to "Management Information" or "Strategic Information"). The dashboard in your example is taken from current activity, and may or may not have any need for data from last shift or yesterday or longer. The short life span of the data's importance leads me to think more of OLTP or ODS processing, not data warehouse. Is my view of DW to narrow here?  ----- Original Message ----- From: "Tanase, Gabriel (GEI, GEIH)"   To:   Sent: Friday, July 30, 2004 9:07 AM Subject: RE: dwlist: Real time DW and the speed of real decisions   > http://www.DataWarehousing.com is sponsored by DataMirror, a leading > provider of real-time data integration and resiliency solutions. > Please visit our sponsor today at http://www.datamirror.com > to access data warehousing white papers and best practices. > > For help with list commands, send a message > to  with the > word "help" in the body of the message. > > From: "Tanase, Gabriel (GEI, GEIH)"   > > > > > > > > > I believe that it's not managers who are the supposed targets of real-time > DWs. > AFAIK, it is telesales people who - allegedly - need analytical customer > profiles and contact/purchase history. > > If all sales people were so rational and analytical... > > > I can, however, offer a genuine example for when managers/supervisors need > to take action within a half-hour from when a dial goes red, definitely well > before end of day. > In a high-volume call center environment (insurance, banking, customer care > etc.), if the ring-to-respond interval or the call length go consistently > "red" for more than half an hour or an hour on certain queues/teams, it > means that one has too few people allocated to those queues / teams, or that > something systemic prevents people from closing calls in a reasonable time > e.g. the computer system they're using is too slow. > The result is that too many customers are kept waiting for too long, which > is "baaad" (unless the company earns a share of the revenue from the phone > company based on call length). > > A call center supervisor / manager *must* take decisions within one hour to > reallocate people or address other aspects of the situation. Otherwise > her/his department will miss the SLAs with their internal or external > customers for that day and there may be penalties. > > > Now, whether this type of report must come from a DW is a separate question. > I guess that, in this particular case, it depends on the capability of the > call centre's phone switch software packages to provide real-time reports or > at least "traffic lights". They usually do, so this kind of a report doesn't > really need to rely on a real-time data upload from the phone switch > database into a DW, then for the DW portal to show the colors. > However, if one has already built the real-time DW upload, then a 'traffic > lights' report in the DW portal, refreshed every few minutes, should be > easy. > > > Regards, > Gabriel Tanase > IT Systems Designer > GE Financial Insurance Europe > GEIS Shannon, Ireland > e-mail: gabriel.tanase@ge.com > Opinions expressed in this message are my own and do not represent the > opinions or policies of GE or GEFI or any of its other employees, > directors, officers, shareholders or affiliates. > > > > > > -----Original Message----- > > From: Greg Della-Croce [mailto:SolutionBuilder2002@hotmail.com] > > Sent: Tuesday, July 27, 2004 10:30 PM > > To: dwlist@datawarehousing.com > > Subject: dwlist: Real time DW and the speed of real decisions > > > > > > From: "Greg Della-Croce"   > > > > I may be a little dense, or maybe it is the type of clients I have. > > Either way, can we discuss the >>Real  > obviously missing the value proposition here. I have found that > > business people make very few decisions/actions on information on an > > up-to-the-minute set of information. End-of-Day > > information, yes. But > > would a manager take an action on information based on the dash board > > gauge having moved from green to yellow in the last 10 > > minutes, OR would > > they wait and see what the situation was at EOD? > > > > Thanks! > > Greg Della-Croce > > > This communication contains information which may be confidential or > privileged. The information is intended solely for the use of the individual > or entity named above. If you are not the intended recipient, be aware that > any disclosure, copying, distribution or use of the contents of this > information is prohibited. If you have received this communication in > error, please notify me by telephone immediately. Any opinions expressed > are those of the author, not the GE Insurance group. This communication does > not constitute either offer or acceptance of any contractually binding > agreement. Such offer or acceptance must be communicated in writing. It is > the responsibility of the recipient to ensure this email and attachments are > free from computer viruses before use and the sender accepts no > responsibility or liability for any such computer viruses. >       
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Jim, At last, something of an append about business value. Great!!!  IÂve tried (unsuccessfully) to spark more discussion on this forum about the business value of data warehousing. I gave up a while ago started a yahoo group and invited over 200 people to join. Again, no success. IÂve achieve no real traction on Âbusiness value discussionÂ. (Details at the bottom for anyone who is interested in joining a yahoo group discussing business value onlyÂno tech discussion allowed.. ;-) no product discussion allowed ;-) Â.)  So I, for one, would like to see more of this style of discussion.  I find it quit ÂinterestingÂ that there is not a single public place I can find where business value of data warehousing is being regularly discussed yet the #1 question I have been asked by every client since 1991 has been ÂHow do we cost justify the data warehouse?Â. IÂve written papers/presentations, conducted a lot of tests within companies, and generated lots of case studies of rather overwhelming cost justifications. IÂve sold a lot of DW projects and many of them have gone on to generate huge value for the clients I have worked with. But still no focused business discussion anywhere that I can find.  On another tack, I think I would be inclined to say I agree quite a bit with Gabriel on the idea that we have but scratched the surface yet as far as using information within the businessÂ.we have again (as Ralph so eloquently put it in his first book) snatched defeat from the jaws of victory.  For me, the day I saw DIS demonstrated in 1991 it was like a blinding flash of realization. THIS IS WHAT IT IS FOR. Driving the company forward. It was obvious to me that using information like it could be used in DIS was going to be the most important business innovation that IT was going to bring since the abacus. And so I changed the direction I was heading and went down the path of DW/DIS 110%.  I was one who really felt that DWing would transform the business community and make Âfact based decision makingÂ the norm in major companies.  But Enron/Worldcom/dot com bubble etc have clearly demonstrated that we are about as far from fact based decision making as we have ever been. Indeed, through legislation like Smith/Barnes/Oxley or whatever it is that has been passed in the US and Basel II to an extent as well companies are being pressured and rewarded for doing what it is the senior management should really be insisting on to run their companies anyway, counting the beans properlyÂ.itÂs not that hard to doÂ..   On the CRM side, I only have to look at my experiences and interactions with major companies who have so-called state of the art CRM systems and data warehouses to see that the change to providing differentiated customer service and customizing the customer experience based on demonstrated preferences and interactions is a long way off.  My bank (St George Bank in Australia by the way), is just appalling in their treatment of me, a mortgage holder for 17 years and never missed a payment. Yet they will tell you they have great CRM systems. And the phone company I was with would regularly cut of my mobile service when I was endlessly traveling and didnÂt get a chance to do my expenses and pay the bill. And they could see where I was!! And they knew it was a company phone!!! And they knew I used to spend around USD1,000 per month which put my in a very high use bracket for mobile!!! But still they would cut me offÂ..  And nowadays in Ireland Vodaphone not only cuts off my mobile service if itÂs not paid promptly, they even charge me 20 Euros to re-connect me!!! Sorry, CRM, differentiated customer serviced based on proven customer value is a long way offÂeven in industry giants and leaders like VodoaphoneÂÂ CRM? BI? I donÂt think so.  Sure, some companies are doing it pretty well, and often they are being handsomely rewarded for their efforts. In Australia the National Australia Bank produces double the profit of each of the other 3 banks due significantly to their 12 years of effort in the DW/CRM space. Meanwhile, I was talking to one of the other 3 a few years ago and their take was that after millions of dollars had been poured into Âthe worlds most advance DWÂ not one cent of profit had come from it. Their words, not mine.  I would like to believe that the business people of the world will one morning get out of bed and wake up to the fact that they can gain a significant competitive advantage by effectively using information in the management decision making process. But I actually believe itÂs going to be a slow process and that we are not going to see the effective use of information be pervasive any time soonÂ.  Why?  Because as I started out at the top of this append, there is not even enough interest between business people to start a public discussion on the topic.   Best Regards Â  Peter Nolan   Post message: bidw-business@yahoogroups.com Subscribe: bidw-business-subscribe@yahoogroups.com Unsubscribe: bidw-business-unsubscribe@yahoogroups.com List owner: bidw-business-owner@yahoogroups.com     
    
</post>

<date>02,August,2004</date>
<post>

	 
       Peter,  What you are describing as a difference in the capabilities of 3NF vs. DM sounds more like a difference in scope.  You are correct that most DM projects tend to limit scope.  However, I have implemented dimensional models where ALL source system changes are captured.  Chris Busch   Hi Chris, I've never said it's not possible to capture all changes in a dimensional model....  I have said that that if you do capture all changes in a dimensional model and you use type 2 dimensions to do so and you also use that model as the model that end users will query then that model will run more slowly than if you capture all changes (somewhere else) and just give the end users the data they need to query on some regular basis.   I have also said that when you have end users in front of the screen clicking their mouse, performance is important.    Best Regards  Peter  
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Gabriel, It was my comment you are responding to....  SA=Stability Analysis. There's a detailed enough description of it in the 'Newsletters' portion of my web site here -> http://pws.prserv.net/ieinet.pnolan/downloads.htm#bm003  Basically it is the process of splitting the data elements on a table by volatility to save disk...something those of us who are older remember doing..;-)...And some of us who don't feel like wasting disk still occasionally do......I was checking the other day and disk is now about 30,000 times cheaper than it was in 1991 when I did my first DW.  Bills was the first book that I read about it in. Others have also talked about it in similar time frames so who knows who was first. I wasn't.  On the statement: "After all a 3NF TV+SA model is not meant to be queried by the user, so it does not need to be easy to query or easy to understand.... "  I remember specifically discussing this point in one of Bills seminars I attended in 1994 (or there abouts). As he was presenting the details of 3NF+TV+SA I asked/pointed out that no mere mortal end user could possibly query it.....and no tools would understand it for years to come.  Bills response was: "The appropriate query tool for this model is called a programmer."  To me, a person who was doing all the could to present information that was easy for a user to understand, this seemed a very strange position to take. For about an hour. Then it made sense.  These models are difficult to query properly. It is possible to build views over them to hide some of the complexity. And in 10 years the HW/SW has gotten much faster so we can hide more and few people bother with SA any more because disk is so cheap....but still, they are hard to query and if you don't know what you are doing you can get lost rows to Cartesian products just he same as in a normal 3NF model only more of them because of the time variance.  I've worked in Life Insurance for years as well as general, and investments and I'm well aware that lots of the guys in those areas like to query data for themselves...and many of them have great skills at it too.  I used to work in billing systems and I even audited a few systems so I know quite a bit about auditabilty.  I am amazed that the leading ETL tools do nothing for you in the space of auditing.  Auditing is important, and is becoming more so in the US/Europe.  We in Australia got the jump on the rest of the world in terms of 'business empires gone bad' and the Australian government introduced a law in 1992 that made directors financially and personally responsible for corporate losses. (We were surprised they were no up until that point in time.)  We got a lot of interest in audit-ability of reporting systems in 1993/4 but after a while everyone forgot auditing was important again....such is life, (Most people have very short attention spans, so they are doomed to repeat their very own mistakes quite often.)  And yes, you are right, give them just 3NF+TV+SA and it won't work....I have never heard anyone propose giving just the archive layer...  Dimensional models have had such an impact because they are intuitively obvious. A good idea whos time has come. But it has been coming for 30 years, not just the last few....;-)    -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:owner-dwlist@datawarehousing.com] On Behalf Of Tanase, Gabriel (GEI, GEIH) Sent: 28 July 2004 10:34 To: 'dwlist@datawarehousing.com' Subject: RE: dwlist: The compelling business case for an archival non-lossy  http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to  with the word "help" in the body of the message.  From: "Tanase, Gabriel (GEI, GEIH)"          Hi Peter, Jim  Please excuse my ignorance, but what does "3NF TV+SA" mean? I believe that TV means 'time variant', but at this moment it escapes me what SA is intended to mean.  On the statement that "after all a 3NF TV+SA model is not meant to be queried by the user, so it does not need to be easy to query or easy to understand.... " (don't know whether it is yours or Jim's), I am 95% sure that my auditors would not agree at all. If the 3NF TV+SA model is used for loading higher-level marts, auditors want someone to be able to manually query it and independently (from the automated loading procedures) to confirm validity and auditability of figures loaded in the marts. Believe, it's hard and long work to query a 3NF TV+SA to satisfy each way auditors want to scrutinize figures... It better be nice and queryable.  It's a SOX world nowadays, and the CEO puts his signature on the balance sheet and the profit & loss statements, which are fed directly or indirectly from some of the DW reports. Less than auditable accuracy and the CEO goes to jail (or so we're being told when rushing to deliver :-).  Besides auditors, in insurance one also has the actuaries. Another bunch of nice people who love querying themselves and taking big loads of data into their statistical packages. Give them just a 3NF TV+SA and they'll make sure the CEO soon knows you're the worst idiot in IT they ever met (OK, I'm exaggerating this a bit; I am in good terms with these people, but this is before our new DW goes live :-).   Best regards, Gabriel  Gabriel Tanase IT Systems Designer GE Financial Insurance Europe GEIS Shannon, Ireland e-mail: gabriel.tanase@ge.com Opinions expressed in this message are my own and do not represent the opinions or policies of GE or GEFI or any of its other employees, directors, officers, shareholders or affiliates.     > -----Original Message----- > From: Peter Nolan [mailto:peter@peternolan.com] > Sent: Tuesday, July 27, 2004 8:52 PM > To: 'jim stagnitto'; DWLIST > Subject: RE: dwlist: The compelling business case for an archival > non-lossy > > >> I did say I believe a 3NF model like that is more able to capture all > versions of data than a type 2 dimension. And the reason I say that is > because in a type 2 dimension where the table will be queried (a basic > notion of dimensional modelling) will typically store data from multiple > different source files and be somewhat denormalised.....hence tracking > changes to every field in the table creates a large volume of redundant > data than capturing the same information in a 3NF TV+SA model. > > >> And in fact, about 8 years ago I discovered that exactly the same > code could be used to build a type 2 dimension as a 3NF TV+SA model if > you are just careful enough about getting data into and out of the > staging area...instead of combining data to go onto the type 2 dimension > you split it by volatility (yes, I even put integer keys onto my TV > models but I only use them as internal keys..).....so discussions about > using 3NF TV+SA models vs type 2 dimensions seems a waste of time to me > because a 3NF TV+SA entity is a type 2 dimension...it's just that it is > split based on data volatility and 3NF design rather than bringing > together disparate data elements to improve query-ability of the > tables.....after all a 3NF TV+SA model is not meant to be queried by the > user, so it does not need to be easy to query or easy to > understand.... > > This communication contains information which may be confidential or privileged. The information is intended solely for the use of the individual or entity named above. If you are not the intended recipient, be aware that any disclosure, copying, distribution or use of the contents of this information is prohibited. If you have received this communication in error, please notify me by telephone immediately. Any opinions expressed are those of the author, not the GE Insurance group. This communication does not constitute either offer or acceptance of any contractually binding agreement. Such offer or acceptance must be communicated in writing. It is the responsibility of the recipient to ensure this email and attachments are free from computer viruses before use and the sender accepts no responsibility or liability for any such computer viruses.       
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Robert, "Nobody ever refers to his writing when providing an actual example of how to execute his methodology."  That's because he does not provide examples in his books and papers. Prism used to sell data models that Bill designed so why would he publish examples? Also, Bill is not a details kind of guy. The recent book by Claudia/Nick goes a long way to actually providing some concrete examples. It's the best one so far on the details of combining archive+analytical. If you are truly looking for such information, I recommend you go out and buy it.  Just because you have not seen something does not mean it does not exist. I'm here to say I've seen plenty of these things and built a few myself. I'm not about to write a book about them....I'm busy feeding my family... ;-)  As far as methodology goes. The modelling techniques are not a 'methodology'. There is an excellent methodology for building a DW that was written during Bills time at Prism but he didn't write it.....and it is modelling technique agnostic. Using iterations you can build whatever types of models you like....I have even used Iterations to implement IWS!!!! Now that was funky!!!!   Best Regards Â  Peter Nolan From: "Harford, Robert M"       Peter,  And one more point. It's interesting that despite the what, dozens of books Bill Inmon has written and hundreds or thousands of articles, nobody ever refers to his writing when providing an actual example of how to execute his methodology. It's always, "... ya I've heard of an example, check out DataVault's home page or check out Imhoff's new book or check out the Data Warehousing Institute class..." Then you are off on some wild goose chase for the elusive "time variant, 3NF data model" that provides the ideal basis for an efficient, integrated enterprise data warehouse that can rapidly feed star schema data marts with all the information (historical and otherwise) that is needed.  To put it another way, it sure isn't remotely similar to: You want a concrete example of acheiving the fundamental object of recreating history? Check out the Data Warehouse Toolkit, second edition, pages 97 - 100, or check out these articles on the web: http://www.dbmsmag.com/9604d05.html http://www.dbmsmag.com/9805d05.html http://www.dbmsmag.com/9806d05.html  --Bob Harford Data Warehouse Architect AlphaInsight  Opinions and views are my own.      -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:cgarvey@datamirror.com] Sent: Wednesday, July 14, 2004 8:56 AM To: 'dwlist@datawarehousing.com' Subject: dwlist: FW: BOUNCE dwlist@datawarehousing.com: Approval required:   http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to  with the word "help" in the body of the message.  From: Claire Garvey   Received: from prserv.net by datawarehousing.com for  ; Tue, 13 Jul 2004 18:37:45 -0400 From: "Peter Nolan"   To:   Subject: RE: dwlist: Dimensional ODS Date: Wed, 14 Jul 2004 01:25:28 +0300      Hi Robert, I'm not sure I understand your response.....  I'm familiar with the book you mention, and the web pages Ralph noted about the book...but the book in question is not written by Bill.  So I am unsure as to how the references you provide point out that it is false that Bill "Publishes descriptions of architectures and possible alternatives that people can put in place, not 'prescriptive rules'".   Ralph did pose the question: What are the detailed implications of administering a "time variant E/R model"? Does this mean date keys embedded in every entity? Begin dates as well as end dates? How many date keys in how many tables do you need to snapshot a complete profile of a customer or a product at a point in time? How do you administer the keys to maintain this snapshot? What is the E/R version of a surrogate key pipeline? Do you even have surrogate keys in an E/R model?  And his append referenced does put forward a lot of questions as to how can these things be done in 3NF while also pointing out that through his effort and the effort of his colleagues vast areas of how to model data dimensionally have been published. A huge task in itself. (I wrote a book once, just an internal one for IBM. It's hard work. I'm not sure people who have never written a book know how much time and effort it takes to write one.)  I never did sit down and write a detailed response to Ralphs lengthy append. To do so would be quite a bit of work...  However Claudia/Nick/Jonathan did what I thought was quite a good job at explaining these things in their book. I've read it cover to cover and hope to get some time to post a review of it to my web site......  And even their book is not a set of 'prescriptive rules'. Their book basically says, if you want to do your archive layer as a 3NF, Time Variant, (perhaps with some stability analysis but there is less need for that now) then here is how it has been done in the past.  That is, "here are our ideas, in quite some detail, do with it what you will." I call that far from 'prescriptive'.  And you will notice that in the book they do talk about having a dimensional model to complement the archival data store.  A colleague of mine and I had this idea of combining archival models with dimensional models in 1995. I don't know if we were the first. Maybe we were. But that hardly matters. What does matter is that this two layer architecture has become a very well accepted mechanism of building a very broad information infrastructure for large companies.  I've built plenty of these myself, and I've built plenty where the client did not want an archival layer and only wanted the dimensional model too...What gets built depends on what the customer needs.  Some customers don't want to pay for an archival data store. It's quite expensive to do if you don't by Sybase IWS to do it with. Probably around 150% of the price of implementing just the dimensional model. Maybe twice depending on whos hardware/software you are buying.  I don't believe a there is a thing such as a "Bill Inmon type II dimension" since I believe it was Ralph who first published the phrase Type II dimension.......  Not sure I understand the dinner for two bit.....where was the original post?  Great to see some spirited discussion.. :-)  Best Regards Â  Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com  ------_=_NextPart_000_01C469CB.95F30459 Content-Type: application/ms-tnef Content-Transfer-Encoding: base64  eJ8+IhkRAQaQCAAEAAAAAAABAAEAAQeQBgAIAAAA5AQAAAAAAADoAAEIgAcAGAAAAElQTS5N aWNy b3NvZnQgTWFpbC5Ob3RlADEIAQWAAwAOAAAA1AcHAA4ADQA2ABIAAwBIAQEggAMADgAAANQH BwAO AA0ANgAXAAMATQEBCYABACEAAAAyMkYyNjY0NzE4Qjc4MTRBODM1RDBGMERFRTg5MEVGQQA4 BwEE gAEASwAAAFJFOiBkd2xpc3Q6IEZXOiBCT1VOQ0UgZHdsaXN0QGRhdGF3YXJlaG91c2luZy5j b206 IEFwcHJvdmFsIHJlcXVpcmVkOiAgICAgADkZAQ2ABAACAAAAAgACAAEDkAYAdBMAADAAAAAD AAlZ AQAAAAMA3j+vbwAAAwAIgAggBgAAAAAAwAAAAAAAAEYAAAAAUoUAAHN5AQAeAAmACCAGAAAA AADA AAAAAAAARgAAAABUhQAAAQAAAAQAAAA5LjAACwAKgAggBgAAAAAAwAAAAAAAAEYAAAAABoUA AAAA AAADAAuACCAGAAAAAADAAAAAAAAARgAAAAABhQAAAAAAAAsAAIAIIAYAAAAAAMAAAAAAAABG AAAA AAOFAAAAAAAACwAUgAggBgAAAAAAwAAAAAAAAEYAAAAADoUAAAAAAAADAAKACCAGAAAAAADA AAAA AAAARgAAAAAQhQAAAAAAAAMAFYAIIAYAAAAAAMAAAAAAAABGAAAAABGFAAAAAAAAAwAXgAgg BgAA AAAAwAAAAAAAAEYAAAAAGIUAAAAAAAACAQkQAQAAAAIOAAD+DQAASRkAAExaRnVwMjphAwAK AHJj cGcxMjXiMgNDdGV4BUEBAwH3TwqAAqQD4wIAY2gKwHPwZXQwIAcTAoAP8wBQfwRWCFUHshHF DlED ARDHMvcGAAbDEcUzBEYQyRLbEdPbCO8J9zsYvw4wNRHCDGDOYwBQCwkBZDM2EVALpuwgUBEw BJAs CqIKhAqAkEFuZCACIGUgBGARGMAgcG8LgHQuIPAgSXQnBCAfoQSQB5DidAuAZyB0EPAFQAEA uHNw aQ6wIQEfEHchITIsIVBvegnwBCBvZtIgBuBvawQgQgMQAyC8SW4EYAOgEPAEIHcFEJsCQAnw IABw HtBodR7A3xjBItEFwCEQCGBzJPEi0zMKwCDAY2wHkCJgbm/BBuBkeSBldhMhGMDmZgSQBCB0 byQg BAAkYxcg0iIgJMFwA2B2aWRnINIDkQDQdHUHQCfAePxhbQtQHxAi8SYAB+AokfsOwAWQdSGx KMIH gCXxIoAZGFBneR/WB0B3YXmJJzEiLi6wIHlhH/D2JyfgJCBlCxEmgwOgKxU3ImAQ4AWQax7g LHAg RMEhMGFWYXVsIBImAHMHgB9wYWcrcQXAMMhJ/m0mAAEgICEfAAfgIyIyvNMh4jFiIFcKwGUm AiDS vyPQILEqwCGxJwAkQHMuseoiH+BUKZJ5CGAmsStyWyMAJAFzMjID8Gwe0Gf/IzARIDCxJEAf EAIQ JdIfEG5lCkAAkC9BIiDAMkF2jwrABzACMCJgM05GIVD7NdIEYmw38CETKdQHkSHi+z5BKuFi JEAo 0TrCMAIBIP8N4AiQPHIgUgnAITAJgCfA/yBiKdAEAB8QPPMuQDY0IcKdITFjA5FBACGQZGwn sP8o QEExILAKwQTwIfAAwDzldybBJFEhoGguEQMgPpNu7zrBAMAgwCQBKCjBKJAFEFdDUAMgJPJv IeFy A/FlvikhBCjRHwAJgAmALh36+lQooHAxMSGgJOFIY0JRNnlAkQVAcwhwPrFzbn4nBUAYwARg DrBD 4QCQbdcDEArBKJA6H+BZOIEuQP8CMCTgMLACIAUAHaErCgDQ/yHwO4Ag1DqhJUErMEBhKuH9 J3Bq BZAFQCLxGMBPUUcB0yDhR3R5Px/gQzT/Ngf3HxBKwAbwayGgImARIE8hP0FBKiBHEiJgMnIE IDk3 wCAtIDEwMCJgNL5POjEmxjkiIeNlYk5BaEECQHA6Ly93W1AukGRibXMAwGcuBaAobS85HNA0 CZA1 Ln1a4G0YoB4EAZFa31vmOO9coFyfXa9euTZff2CAHfTILS1CJ3AgSArAOsH/CzEeElTdBxAQ 4CGh UkEeVcxscBDwNtFpZ2CgHfr+TyGQAwACIC4BHsEqAAfQ2y4BH1FtJ7Ar0G5J+2rP1x5FY+Bs oU8F EGcLgCrhvk0HkCYwMpBsox30RgNhh05AaiEEkC1kd2xHgZ5APPJCZiDRXAIgWwDAswMQTiFj ZwrA J+B5b8PVTcByA2ByXAJdHfQGYNsCME5AVwmAHwBzPPBMAeZKMcAnsDE0ImAB0FxwoCA4OjU2 EWBN SmatTkAnb29wdydzBXVSEydOQHZ0TkBGV05AQk/wVU5DRXkFdt9cEU5APEFwKdIHQB30GMBx de9y YAmATkBrjwpgqTFiNhm/cMMo0SGAaNEfQR7QYiewvTFiTXJjImAvACcQYSoi3x30PgUFwFJz B0At O9M8879AtkciJPIgkQMQQFFjTYHvBvAscGjCSfVQgnE6MSoA/wCQUlEIcIC2KIF0ISTgBUDf YKpy Kx30KJEA0GNtkUIMtylEIaIKsHAoUiTyYiCh3ynBKqEN4AeQSftGBbEh8O9nEEXEemJPEW0D gSWQ VjJvHsE9IW2Ui1c8cSV6RC3vfOIgoXqvXBE+RcQh4R30/ndkgS6QkGI38AuAIdMng98i8SHi kmWP XG6zQwthH1FeR3Gzk1Bxn3KjPh30Un8FkFCRfUIDUinBESCbsC7/HwBntmBigWGU34s2YFM6 wnY8 ek+VeDs4EApQImAxFjN0YnT0MXVQMzc6vDQ1V9BccFgQbkoiHZNvB7AG8ABwN/A8jeAdsUD/ p2Mn YKcBnKl2IqHvlWl4LfRSRXj4RAdxAIECICrh6E9EU2S3ZXOjo/F1MDGkRzAxOg4wr6A4IDgr MDOl lrBvsXtIaf8H8Y5wACAiYB30LyBw8Etx+UxUSSAlQShRAZAewThxvygCgMOZULYiHfqzsmZy Qf+p gArBliY0VDhyUZJXAyTy+1pFV0VSB0BnILPiCYAd9O8BoFRWIyIusWK8GZeylHP/RyJJYrQB JHaB YSOCH9Ad+v5TKKC0gCswtJFMYyRBKJL/K9Ih8SgjhlEHkThyPgUfdN9URUkySUId9LdwbELW I4P/ pnB4kKmBWTEhUgUDaMMmk99mJUxxaPQfgAQQaQJgksU/B0Cn4kcBJ+A+cj3SZW//K1JDUkrz KbEL YIwAJ0IFQG4nKdDHZi9BcjHAB5An/y6gsY+dQLrjKiDJUyHEvfb6Oh30VyEiOLIh4gEAAZC/ AxBB MQdwC1BH0cfIZE3AHwMAILAGcSpCO7wgRS/OUh30PURTwERvPmMsw/cDkTzxHxBrm9AEIETg jnC+ ZEnBl7In0iexuUF0U7H+QkDgl8HYIsU1JECWpTtA30gB2KEewdrDU8BIK9EDgf+fo9hVl8Er wt1j AZFZ0iKA/zhjSZIogR30TMBDoMcAtAH/TwIrQo2SA2BAIFAFMLAmIN8okAeAg7E/sSnCZBtw S0Hf TuLEBAuBi2QHcT+yRSvR/9+F1Egh09hzKJFxIVGxl8P/gJLg1VPA0eMo0ZZ31icn4f+tEuJ0 TGED YJuQ2EQfcAUg/ztAC4DlkNchOGMn0SQSL0H/7CsgMruF5PXWIT005aUeWP8owkOgjeCFw8K1 3JHX Qkry/zrBQmGSIhhQUlO99i4Bwcb/HfRDUlkk14Eg4AQgjnAicf8fAZfBPLKNYSthxbFK0R+S 7yDS xGchEANgdWeQKLId9P8BERhhuaf7tSuSKNEYMYJx/meUgTwRjpE2ISRBK5g9Q/8842xEKiCs 50Ph 7mOOcCmid8bFSeAf4EElITKRDJBzp72jIaARIGxmH9EotIB/JHBNQSTgbEQ0ZMLxImBqP+Lh KmIg U21CHvKhoklC/k0f1hDxHtCXAbywLxGz2P+C5cuEIiAooe5yHwAn4iR3/TRUaydgNEDegxtw llE7 4u8k8vu1IaCLVWHYcChzJHLzK3EfAC4ptnsK9dAiiDL/IoBqMCTjD0RFAdLGtaYogt+60y4A JxAg 4EXwebuF8pP/H9BKwd+B+VGXADHAjlK94f0SZGKIQiMACIO2VmN13SGLJ9OakXUqIGEvTibw +Gsv Sq0xIRHYAdAxIiL/tHEl8meRQlEuABb2OgEe0O5qZBEhMPtVeMyRaKFQ1P/3SJfEcmC8dC8U UtHT IZEy/yfiKJEhRCTxfkXLkBPDMpD/TEEyMjvTKJHJcU7ifTBpUv/9Aksx6AJ0oLoyiDG2FEn7 //IC 7hMfuL527AEjUf0RzU//zlEtoTghH+UE5T9BR+FNcv0uU2n9IOaCTrPB4d+E43H3ZhIK0cyg eSIC jhE8okCQ1lQ74RhUVjw2KI3hOnD/4PBFxDljRGEXcKmA2iBIEf98YC0ASWG89UyDgmGMIUmS /8VF OtOJkQxhSPLuMjQl/xL/SzE6cQGk+BZUko9wviC/7P8rQEkzQJCXUcGCmtGIcj7S/y0SvdKN giOD 0rRAkN+BRdP/SzEbQ+aBlqW/sqcwtHEsgv9JBMWgpsCd8ynbKwDxTi1z/8ZiS3GPEUkFl9a4 seox n6H/wfBRwVQwu+QBYdTjAC//df8ho+GSUZJUgy60UdGMU1Ny/5lQBCDxS/14/QLUYQ1ktID/ xhD8 QijRO4L9AnDRF3AeYz9JB9az24Y9kkbP3jMxOe45YnC0cfgRJ80gDFMtQb+6MLoh0kXiMLTh zpVN LPD39+FS1QjAQsR2CDJ0kVvQ/78h63AHsdHj86NWROn0+nP9+zZ0lwAvJshpN5Vw0Rcy/9mT 2/SL 8cewgTGEcGYg1eD/kRBw8P0QBOV9EBaQ1OTZk/ZiggAg4m6hoVZBvkNfEL+FQL4gziBaJKGi zKBy AwH/4XJcwY8xSkwgc12ijqEUgf8zAZiExdFp8APSuZRi3/jB/1MV9nWGMhGR0DG+s9Xi1/H/ SQcv NclBhYB0kS2y4BLSgves2NZZwdFvJnHR4yNBM6L/Y0L/oPKi/sGFkBtDSMLi1//f8lahwAyE ceLW 32JSEi22/49wdKChomiaSZoH4xbzHae/rPIK0S4ELUVR9IFhU1Rw8YfSSVdTdia+0T2RCMB+ UIIA LEDJwBTm+sHJQTH4NTAlmHaeQENiJTJINv8ecgXzar3/dFPrWRBDYm3EX/nTblLQcAgjjKIv iPBm 31kQOwLmg5rRvPB5lZIP/P93Be0xCxHVETQHhGIecglgyw0BL5MixlNJbtawl9HyeSLhSUlG bacw jRFDcf+0gIPmPdLBsbrUCnJTkwH4/zik+rB3wai1hwR9KCZ0zpv/puC0H/w1XeEPsEBBNZJZ Ib8X cY2jZmQcMkjC42Bp2oH3a4YkUvE7R/6RJXPF0DxlfxNwU6BZ8dyRrHDi0Y1UIPw6LTZAmXra YIqx nVCbkfNvwJPlJ2GlpaaJrbfVIH5XorgZkBORpFC1AZ7VTUcdUPjxplArMzWkIDgANzkgNTgx IDd8 MzLltjygunKmUBwAdKBwOi8vd5/wLqfMBRhUfaGAAAAeAHAAAQAAAAEAAAAAAAAAAgFxAAEA AAAb AAAAAcRpodwZmgz9O0QzRjKhOed7FxsuGQAJ45BgAAMALgAAAAAACwACAAEAAAAeAEIQAQAA AEEA AAA8OERCODcyRTA3QzgwREQ0NkE3REM3NDQ4NkRGRkQ5NTc0RTJBNkRAZG1jbnQwMDEuZGF0 YW1p cnJvci5jb20+AAAAAAMA/T/kBAAAQAA5AFCp95XLacQBAwDxPwkEAAAeADFAAQAAAAoAAABI QVJG T1JEUk0AAAADABpAAAAAAB4AMEABAAAACgAAAEhBUkZPUkRSTQAAAAMAGUAAAAAAAwAmAAAA AAAD ADYAAAAAAAMAgBD/////CwDyEAEAAAACAUcAAQAAADIAAABjPVVTO2E9IDtwPUdPVitET1M7 bD1I UlNOVFNFLTA0MDcxNDE3NTQxOFotNzIzODcwAAAAAgH5PwEAAABSAAAAAAAAANynQMjAQhAa tLkI ACsv4YIBAAAAAAAAAC9PPUdPVitET1MvT1U9RENNRVRST0MvQ049UEVSIFJFQ0lQSUVOVFMv Q049 SEFSRk9SRFJNAAAAHgD4PwEAAAASAAAASGFyZm9yZCwgUm9iZXJ0IE0AAAAeADhAAQAAAAoA AABI QVJGT1JEUk0AAAACAfs/AQAAAFIAAAAAAAAA3KdAyMBCEBq0uQgAKy/hggEAAAAAAAAAL089 R09W K0RPUy9PVT1EQ01FVFJPQy9DTj1QRVIgUkVDSVBJRU5UUy9DTj1IQVJGT1JEUk0AAAAeAPo/ AQAA ABIAAABIYXJmb3JkLCBSb2JlcnQgTQAAAB4AOUABAAAACgAAAEhBUkZPUkRSTQAAAEAABzBZ BPOV y2nEAUAACDCGepiYy2nEAR4APQABAAAABQAAAFJFOiAAAAAAHgAdDgEAAABHAAAAZHdsaXN0 OiBG VzogQk9VTkNFIGR3bGlzdEBkYXRhd2FyZWhvdXNpbmcuY29tOiBBcHByb3ZhbCByZXF1aXJl ZDog ICAgIAAAHgA1EAEAAAAzAAAAPDVEQjBDQjE4MzNFN0Q0MTFCMjlBMDAwN0U5MEMyRUJEMDUy M0E1 MzNAaHJzbnRzZT4AAAsAKQAAAAAACwAjAAAAAAADAAYQl9c8CAMABxBpEQAAAwAQEAAAAAAD ABEQ AAAAAB4ACBABAAAAZQAAAFBFVEVSLEFORE9ORU1PUkVQT0lOVElUU0lOVEVSRVNUSU5HVEhB VERF U1BJVEVUSEVXSEFULERPWkVOU09GQk9PS1NCSUxMSU5NT05IQVNXUklUVEVOQU5ESFVORFJF RFNP UlQAAAAAAgF/AAEAAAAzAAAAPDVEQjBDQjE4MzNFN0Q0MTFCMjlBMDAwN0U5MEMyRUJEMDUy M0E1 MzNAaHJzbnRzZT4AAObX  ------_=_NextPart_000_01C469CB.95F30459--       
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Claire, I thought I'd just add my 2 cents worth.....  Iâve been an advocate of using the DW for marketing for 13 years nowâ¦â¦.and I still firmly believe that the goal of âsell more stuffâ is one of the top goals of any commercial organisation. However, I strongly agree with you that âsell more stuffâ is usually interpreted to be âwe should throw junk mail out to peopleâ and âwe could call people at dinner time and irritate them by trying to sell them xyz productâ. The US is really bad at thisâ¦..(When I was in the US 2 years ago I was ill for a few days, and I got 8-10 telemarketing calls a day on a phone line that was a new number that I never used and never gave to anybody!!!!! These people knew nothing about me yet they were trying to sell me stuffâ¦..hhhmmmm.)  In projects I have worked on we have been much more sensitive to the consumer of our products and services. We approached customers where we were making a valuable offer, in line with what we knew about the customer, and in line with what other people like the customer have found to be of value. The result? Our âjunk mailâ campaign purchase rates hovered between 0.8-1.2%. Our more âsensitiveâ campaigns hovered between 15-20% purchase ratesâ¦.with one star campaign hitting 30% new product purchase from direct mail no lessâ¦â¦we were also able to achieve a 64% retention rate in one highly personalised campaign sold directly to existing customers through agents.  Good quality data is a foundation of such efforts.  Personally, Iâm of the opinion that if we are representing reputable products and services that our customers consume anyway (only with another company today), or would be of great value for the consumer to have, then generating a win-win situation for the consumer and the company and persuading the consumer to put their business with us is providing a service to the consumer that is of significant value.  I always propose taking the that the consumer is intelligent and (mostly) rational. Provide them with the opportunity to buy what it is they want to buy anyway, treat them well, and they will return. If that takes a DW, great, but often it just takes good manners and a few minutes of oneâs time.   Example? I am away from home a lot and I love to listen to music. iRiver make the best MPs players bar none. I wanted to âupgradeâ my iRiver player from the imp-350(purchased in the US) to the imp-550. But I was in Ireland and the reseller had not bothered finding a retail outlet yet for iRiver gear. Creative were everywhere and the reseller did not see the need to sell anything elseâ¦.â¦but I chased up one of the retail outlets (www.peats.com for those of you in Dublin) and begged them to get the new imp-550 in. They were really nice about it and decided to get an imp-550 in, just for me. So I said Iâd buy the ifp-180 as well since they were so nice about it. And I thought that would be that.  Wellâ¦.., I went into the store the other day when I finally got home to say âthank youâ personally to the guy who got his company buy me 2 iRiver products, obviously at a loss. His take? He said they should be thanking me as the 40GB hard drive iRiver mp3 player was now outselling creative 2 to 1 despite the much higher price tag. He said none of them had heard of iRiver before I mentioned it to them and now most of the staff owned one!!! He told me they have no trouble selling them because everyone selling them owns and as an owner of the product they sell âIf you want the best sound, buy the iRiver player.â A very convincing sales pitch.   The bottom line?  1. Now where am I going to buy all my electrical stuff from now on? Even if it costs a little more? My pals at Peats. 2. Happy customers tell at least 10 other people. And I figure at least a few people on this list must live in Dublin.. ;-) (And iRiver is everywhere.) 3. And if the good folks at Peats had good quality customer data of people who had purchased quality music gear in the last 3 years they could contact them and let them know they now carried the very best MP3 players. A lot of music lovers would love to be emailed/called/paper mailed to hear that, and some of them might even buy oneâ¦ âº  This, in my opinion, is an excellent reason to have good customer name and address data in the DWâ¦.well, maybe that was more than 2 cents worth.. âº  Best Regards  Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com   -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:owner-dwlist@datawarehousing.com] On Behalf Of "Claire McFarlen"@datawarehousing.com Sent: 21 May 2004 05:26 To: dwlist@datawarehousing.com Subject: Re: dwlist: Data Quality and cleansing ROI  http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to  with the word "help" in the body of the message.  From: "Claire McFarlen"     I've seen companies pour buckets of money into processes and tools to perfrom data cleansing on name and address files. I've never really understood why this is desirable. In my view a data warehouse provides an environment to process large volumes of facts-based transactional data, and data mining for observing trends over time of customer activity such as purchasing behaviours and regional or other demographically focussed inquiries. Early implementations of data warehouses talked a lot about encrpyting personal customer information including name and street address, to protect the privacy of their customers and even their security. I don't hear much talk about privacy of personal data anymore, sad to say.  Personally, I don't see much use for this type of information except for the purpose of targetted marketting campaigns that involve a lot of junk mail and unwanted telemarketing. Legitimate mailing and customer lists that are used for proper business purposes, such as invoicing, customer statements, notifications or vendor communications are usually produced as a function of standard operational systems reporting.  I'd recommend that you should listen to what the business is telling you.   Claire McFarlen Data Warehouse Consultant Clay New Media         
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Neil, Well, I guess I should respond....;-)  "I think the 3NF is indefensible."  Well, I agree just plain 3NF for a DW is indefensible and in a number of cases of NCR implementations I've had the opportunity to see the TV bit was somehow completely left off such important entities as customer/account.  If you include 3NF+TV+SA I'd disagree.  There are some absolutely compelling reasons why this model is a useful and valuable model, as I have shared here. Especially in the case where the questions to be posed could not be reasonably known prior to the design of the DW.  Dimensional models have some limitations on them and recording every value of every field in every operational system that stands a chance of being valuable in the future and still be fast/easy to query and understand is one of those limitations.  "First of all, there is no detail data that shouldn't be queried, and if we move the detail into the marts, why did we need the 3NF in the first place?"  What you are saying is that 'all detailed data should be queried'.  Who says all data should be queried? Some data may never be queried.  If a company cannot cost justify keeping all data forever some data will be lost and perhaps never queried.  The designer must decide what data will NOT be kept and will therefore not be queryable by the user or anyone else. The designer must decide the retention time of data, and if data is to be archived, the archive mechanism, the costs associated with it, the delays associated with it and balance that against a reasonable cost benefit analysis.  In this kind of model the transactions need to be in 'both places'.  Also, just by the way, in 1994 I learned the lesson (the hard way)of putting the real keys into the fact tables so that a fact table could participate in both the archive layer as a 3NF table as well as in the base layer of the dimensional model. So transactions, and even snapshot fact tables, can be designed to participate in both layers without needing two copies of the data. (A tip for those on the list because I see many DWs where the transactions are needlessly replicated in both....;- )  Indeed, this point is one of the few very minor points of disagreement Ralph and I had over the years. I believe there is value in keeping the real keys on the facts and Ralph has recommended that real keys are taken off the transactions. (So what...We are both entitled to our opinions, and he's a much better writer than me anyway..;-) )   "Also, if it's hard to understand and query, doesn't that make the ETL job (both into and out of) more complicated?"  Yes. ETL into and out of the archive layer is complicated, time consuming to write, time consuming to run, and difficult to change. In a word. It is EXPENSIVE. Really, really expensive. The whole concept of an archive layer as well as an analytical layer has been the MOST EXPENSIVE EDW proposition for years now.....I've never argued that it wasn't.  This is one reason why many companies don't do it. Because they cannot see the cost benefit of doing it. Very reasonable.   "3NF was designed for one purpose, transaction processing, it has absolutely nothing to do with being neutral or flexible."  Well, I wasn't there, but that's not what I read when I read Date/Codd.  I read 3NF was a design technique aimed at reducing redundancy of data. One side effect was to make updates more efficient.  Remember, at the time 3NF was developed disk was around USD300,000 per GB!!!! For Codd/Date to make relational sound like a good idea minimising the amount of disk was important.  Codd/Date were competing internally in IBM with IMS which did not require the duplication of keys in different tables, and that made IMS faster and cheaper. A relational model requires more disk/processor than a hierarchical model and 3NF was an effort to narrow the gap.  Since then, people have claimed all sorts of things of 3NF. From 'application neutral' to supporting the 'natural order of things which is why it is called the 'normal' formal'. You are correct. It is all crap. It was about promoting the relational model to IBM.   All the history aside....  The bottom line is many organisations around the world have found great value in archiving information without a clear view of exactly what they were going to do with it.  If an organisation is in the category where they really can justify the archiving of information without a clear idea of what they will do with it what other options does one have?  Building a (non-IWS) dimensional model is not going to enable the company to achieve what it is they want to achieve.  (Or at least, in 4 years of thinking and trying I was unable to get a dimensional model to support both query requirements and archive requirements. And a number of the 'best and brightest' put their minds to this very problem archive data in a dimensional model because we knew the dimensional model had to stay. We failed. Simple as that. Which is why the archive layer has become a widely used implementation.   The 'analogy' used is like taking a photograph.  We don't know what questions we might ask about the organisation (or the external environment) so every so often (usually daily) we take an 'electronic photograph' of the company as it is at the end of the day. (Notice that in most cases we don't try to take multiple photographs per day, though I did in one case, every 8 hours.)  At some point in the future someone asks a question about the state of the company at some point in time in the past. Since you know you have a 'photograph' at the end of the day you know you can answer the question of the company status at the end of the day.  If the user then wants some kind of trend analysis on this new question you know you can do that too because you know you have a photograph at the end of every day. So you can build daily/weekly/whatever trend analysis.   Remember, the 'architectural object' I am talking about is the answer to the question: 'Give me the answer to any question I might ask, even though I don't know what the question is.'  A dimensional model, necessarily, is the architectural object that is the answer to the question 'Give me the answer to any question I might ask from the set of information of this groups of facts and dimensions'. And generally we limit the number of facts and dimensions.  I agree, and I would argue 95% if not more of ALL business questions can be answered from a well designed dimensional data warehouse with a broad coverage of data.  It is easy to make the case the other 5% doesn't matter. Much easier than it is to make the case of spending the same amount of money again to get the other 5% of answers.  But I challenge anyone to answer the 'unknown' question from a dimensional model that has a defined set of facts and dimensions (ie. lossy) that can only be answered from the 'lost' data. It cannot be done.  To be able to answer the 'unknown' question one requires 'non-lossy' data models which are at least understandable by the technical people who build them. To provide great performance of queries to end users one requires dimensional models or a ton of processing power (teradata).  Now Neil, you may disagree, you may call this all BS and you have every right to your opinion.  I'm just putting forth the fact I've seen these kinds of models, I've built them, I've seen them answer questions that the best designer with the best intentions would not have covered in the dimensional model. I've seen answers generated by such databases lead to multi-millions of dollars in profit for large organisations.  From the purely practical financial point of view of a company it hardly matters what 'modelling technique' is used if the company gets a multi-million dollar kick. And I am very practical about these things....;-)  Actually, it pains me to see on this forum so much discussion on 'modelling' and so little discussion on 'business value', despite my best efforts to get such discussion started.  I am guessing only 2 people from this group signed up for the 'business discussion only' yahoo group I started.  And with such little interest in the >>REAL VALUE my opinion is we as a group deserve the poor reputation we currently have in the business community at large.    
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Robert, You are changing the words and misrepresenting what I wrote.  I wrote: "An archival layer, (ala Bill Inmon) can be developed on the basis of being non-lossy if one likes."  I did not say it the CIF was defined to be non-lossy and I have not shifted the argument.  Further, if you make accusations of people peddling fraudulent ideas, perhaps you would be responsible enough to actually read the responses that some people spend their time and effort to make to your comments.  I read your comment: "I have not read your extensive posting thoroughly given its length." And I ask myself, why would I bother spending my valuable time assisting people like you on this forum if they have an attitude like this.     
    
</post>

<date>02,August,2004</date>
<post>

	 
       Some days we just get lucky in being about to point out the 'cost' of bad data quality....  I've always said that ignoring data quality is something like playing Ostrich.  I am reminded of a bank I once worked with that turned out to be on the wrong side of it's capital adequacy rations....  But tonight, when I watched the news, I picked up my best example so far of the 'cost' of data quality and audit processes to make sure that the information passed up the chain is accurate.  Of course, I am referring to Colin Powell live on the evening news apologising to the American people about some 'data gathering and analysis errors' in a recent report on the state of the 'war on terror'.  I think the next time someone asks me whether data quality is really a concern I might just reply ÂAsk Colin PowellÂÂ;-)  Best Regards Â  Peter Nolan   
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Jim/Nick/All,  1. It is true that a CIF will cost much more than a purely dimensional BUS architecture DW as proposed by Ralph. No Question. Perhaps even double.  2. However, there are a couple of classes of questions and information which I do not believe are well covered by the BUS architecture/Dimensional models.   I will explain each in detail:  They are: 1. The increasing need for integrated near real time information aka. Operational Data Store. (Just look at how many people are buying middleware believing they can integrate information 'on the fly' with no ODS.)  2. The need to support questions which are not known and cannot be reasonably expected to be known at the time of construction of the DW.   1. ODS. With the advent of the call center in the mid 90s there has been an ever increasing need for a 'single view' of customer information in order to service the customer. Further, with the drive for things like 'loan/credit card approval over the phone' there has been an increasing need to integrate data more and more rapidly in order to support tactical operational decisions like 'do I approve this loan' or 'do I cross sell this product to this customer on the phone'? (I mean the customer had better not already own the product that I am cross selling.) These are compellingly important business processes.  The ODS actually evolved after the DW when numerous DW projects were hijacked by the call center. I worked on a number of projects to pull parts of the DW out so that the call center could use the integrated customer data and the analysts could use the DW again. Then Bill published his ODS book and I think 'So that's what we've been building, now we have a name for it, great!!!'  The BUS Architecture, as I interpret it, does not do so much for me in integrating information for operational tactical decision making and customer service. Indeed, I believe (unless using IWS) it is not possible to support the update requirements of the ODS without using 3NF to achieve the transaction rates on current hardware in large organisations. The star join, by it's very nature quite time consuming and expensive to perform makes it a worrying prospect to try and build one that will be updated by transactions.  This is also the stated opinion of Gartner and a number of the large consulting organisations. Doug Laney might let us know what Metas current position is on the concept of building an updatable ODS using dimensional techniques.    2. Undefined and impossible to predict questions. It may come as a surprise to many on this list that if you spend a lot of time with senior managers there are a LOT of questions that come up that no-one had asked before. Have not even thought to ask before. Have not even considered if they might even be important before.  Dimensional modelling, buy itÂs very nature, tends to focus and limit the amount of data (in terms of number of fields) to those items that are necessary to run the business on an ongoing basis. That is, the information put into a dimensional DW is typically information where there is substantial reason to believe that the information will be of value. I've used this side-effect of dimensional modelling often. It helps get the project done and get value out of the project. This 'side-effect' has also led to the ridiculous situation where everyone believes and many vendors present the concept that it is possible to build a 'data warehouse' in 90 days. I must confess to being a part of this for some time.  However, this approach does not discount the value of answering the 'unknown question'. Indeed, the 'Business Requirement' from the (incredibly smart) Director of Marketing for my very first DW was, and I quote: 'I want the answer to any question I care to ask, and I want the answer before I forget why I asked the question.' (And I was a pup SE at IBM at the time.)  The only way to make sure that you can answer any question that might come up at any point in the future is to capture all the data that occurs within the organisation. ALL OF IT. Now, that's a bit much so some decisions need to be made about what to cull. However, such archives can be of tremendous value.  Example 1. Actuarial analysis. Setting the price of life insurance policies is tremendously difficult. Keeping excellent records of all customer/policy information, as well as the general population, over an extended period of time is extremely valuable. It can very well make or break a life insurance company over an extended period. That's why the actuaries are so powerful in those companies.  Example 2. Workplace location. Asbestos. It's a big deal in Australia. Many people have sued companies for many millions of dollars claiming they were working in an environment where asbestos was present 20-30 years ago. Now they come forward with 4-5 witnesses to say 'yes the person was where he claims he was' and the companies have had little defense. Had they captured the work locations and durations at work locations of workers they might have a better chance to defend themselves. One might say, 30 years ago we didn't have the computers etc. That ignores the fact that in 20 years time there will be something else, and companies that have not kept records of where employees were will suffer the same fate as many Australian companies over the last few years.  Example 3. The dreaded consultants. How many organisation have had some consulting group come through and perform some 'assessment' followed by some recommendation about what to do next?  Most fortune 1000 sized companies.  When McKinseys came through one of my clients what did they do? They had about 200 questions of various measures they wanted the company to produce, and their plan was to 'burn money' while they were waiting for the answers. Interesting, they got one of the consultants, sat her and I down together, and the deal was she read out the questions and I answered them using DIS/Metaphor. We did the lot in about a week. This was for a $A10B funds under management conglomerate of insurance companies. No small outfit. McKinseys were a little miffed at being given all their answers so quickly. The point is, when we designed the DW, there was NO WAY we could have known the questions McKinseys were going to come in with 2 years later. If we only had dimensional models and not an archive we could not have done the job. The numbers produced would be used to decide the fate of the company. It doesn't get any more important. The question at the time was whether the owners of the insurance company should get rid of it and move on. Minor business decision.   Example 4. The board meeting. Who on this list has been a regular attendee at board meetings of big companies? For those that have not been this is what happens. Someone proposes spending umpteen gizzillion dollars on the latest and greatest 'whatever' called project X and the board tries to decide yes or no.  It is the job of board members to ask questions of the directors/senior managers of the company to ensure that project X is in the interests of the shareholders. To do this they ask questions. Rarely, if ever, are all the questions answered at one meeting. So the decision is delayed to the next board meeting (usually 2 months) so that the questions can be answered. And what happens at the next board meeting after this left over questions are answered? Surprise, surprise, more questions.  And in big companies itÂs not just Project X, they have a whole alphabet of projects to decided on, on an ongoing basis?  A dimensional model, which is extremely difficult to build in a non-lossy manner because of performance degradation, does not support this so well.  At one client (many years ago), we put a DIS/Metaphor terminal in the board room and we sat a marketing analyst at it (not an IT person) and his job was to answer any question that came up in the board meeting in a maximum of FIVE MINUTES.  The benefit. The board could make decisions in an hour or two that used to take 4-6 maybe 8 months. That very reduction in the time taken for the management decision making cycle has another name, 'competitive advantage'. If a company can 'change it's mind in 2 months rather than 6-8 months it hardly matters when they make the wrong decision because they can change it quickly enough.  These cases are real cases I have worked on and I have seen many other similar cases that others have worked on.  So, though the non-lossy archival data store is expensive, complicated, difficult to understand, impossible to query with (most) tools the value of doing so is compelling to some organisations, particularly Insurance companies and Banks.  They are so hugely expensive that I tried personally for 4 years to figure out a way to do away with the separate archive and just keep a dimensional model. I failed. Some of my colleagues, people who are the 'best and brightest' also tried and failed.  Sybase IWS succeeds. IWS enables the ability to store archival data in a non lossy form inside a dimensional model without the need for separation of archive and analytical data.  Further IWS, as far as I am aware, is the first dimensional model that goes so fast it is possible to build the ODS on top of it. I know. I've done it in a company with 18 million customer records. (Though still waiting to go into production last I heard.)  As Neil points out, as hardware goes faster and faster there will likely be a collapsing of these separate physical databases. I believe that in the 5 year time frame the ODS/EDW/Analytical Layers will be able to be collapsed into one single model based on IWS design techniques.   So, all you 'DW' folks.  The acid question of your DW efforts for you to ask yourself.  If a DW is partly defined as 'supporting the management decision making process', would you put the tools you have selected into the board meetings of your company and guarantee that you will answer any question the board cares to ask inside 5 minute?  If the answer is 'no', who cares what modelling technique was used?  That is 'supporting the management decision making process' at work.  I wish more companies would do this. We might have a few less Enrons/Worldcoms etc.  Best Regards Â  Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com   -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:owner-dwlist@datawarehousing.com] On Behalf Of jim stagnitto Sent: 22 July 2004 05:49 To: dwlist@datawarehousing.com Subject: Re: dwlist: Outback Challenge  http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to  with the word "help" in the body of the message.  From: jim stagnitto        Hi Nicholas -  As always, a thoughtful letter, thanks.  My issue with the CIF has never been that it is incapable of meeting business needs, just that it is so woefully inefficient in doing so. Not "right versus wrong" or "possible versus impossible" - rather "efficient versus wasteful". And this distinction, I submit, is neither "academic" nor "subtle" in nature. Or in business. The evolutionary ash heap is filled with interesting and sometimes beautiful creatures that were [key word] just a little less efficient than their competition.  But the CIF - let's face it - is "dramatically" inefficient. Consumes  more, delivers less. From a ruthless Darwinian perspective: doomed I fear. It stubbornly persists [IMHO] largely because there still exist dwindling and isolated pockets within large corporations whose priorities, for whatever fleeting reasons, are artificially skewed from  those of survival of the fittest. Places where one might perceive - ultimately incorrectly - that money and time are something less vital /  real than oxygen and water.  How many members of this community would knowingly implement a CIF architecture if building a data warehouse for a self-funded startup? Very few - I suspect. And these CIF-enabled startups would then be at a significant disadvantage to their better informed, more nimble, and more liquid competitors. Right versus wrong, possible versus impossible - interesting avenues of discussion certainly - but ultimately less relevant to what must survive, no?  In the interest of lively discourse,  --Jim Stagnitto           
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Doug, ÂI hate Inmon's et al continued redefinition of the world in order to suit their arguments. I don't know any users who can tell if they use a class 1, 2 or 3 ODS or even if they are farmers, explorers, or whatever. Why is this important?Â  Perhaps a little harsh....  Definitions and ÂWhy is this important?Â Definitions are important so that we know what we are communicating about, exactly. Our IT industry has fiercely resisted the process of turning it into a reliable construction activity like building a skyscraper or a bridge and one way in which we have resisted is by refusing to actually create a useful definition and agreement of what we mean when we talk about something. At least when we have a definition, we are agreeing on what we have defined and then we can clarify Âdis-agreementsÂ.  Bills ÂearlyÂ definition a Data Warehouse is a classic example of someone taking the time to write a concise descriptive definition of an architectural object and then describe it in detail. And sooooo many people have tried to redefine what a DW is. Every vendor for a start.   Let us not forget that Bill specifically: Â Has been waving the DW flag since the late 80s when none other than IBM tried to put him out of business. Â Has been rather consistent with what he has published over many years. Some would say Âmonotonously soÂ. Â Publishes descriptions of architectures and possible alternatives that people can put in place, not Âprescriptive rulesÂ. Â Publishes observations of what he sees organisations doing and puts forward his own opinions/views on what he reports.  The vast majority of what he has published has been excellent food for thought. My clients (and I) have benefited greatly from what he published and all Bill got back was a few book royalties and a seminar feeÂ.not much reallyÂ..  Often times what he has published has been Âwork in progressÂ since he was often talking about early efforts in a new area.  Sure, some people might take some pieces of what he has written and criticise it. But who of us has written more or promoted the cause of Data Warehousing more in the last 15 years? Only Ralph is in the same category, I would think, with his rather stunningly successful book.  I think you will find that if you go back to the 1992 edition of ÂBuilding the Data WarehouseÂ right through to Building the CIF you will see quite a remarkable consistency of evolving architecture and thought. Some areas are ÂdatingÂ such as ÂStability AnalysisÂ. But then again the driver of stability analysis was to save disk and nowadays disk is around 10,000 times cheaper than 1990 so there is less pressure to save it.  Compare this stability to other areas of IT.  The one I like to point to as a Âchanging standardÂ is embedded SQL, ODBC and ADOÂ.embedded SQL was adopted as nothing less than an ansi standard and it will no longer be supported by Microsoft in their next release of SQL Server. Microsoft promoted ODBC over embedded SQL. And now ODBC is being ÂstabilizedÂ in favour of ADO.net!!!! Amazing. All that re-writing of code just to access data!!!  A more interesting thought might beÂwith this much public information around on data warehousing and ODSs now, how come so many of the projects still fail? It was understandable in the early 90s when building a DW was a very tough thing to do. (I have my own theories, of course.. ;-) )  I recall that in the 2,000+ pages of Metaphors documentation on DIS there was 1.5 pages on the star schema and the .5 was a picture of one fact table and 4 dimensions!!!!  Back then there was almost no public information about how to go about building a DW. Now you can call Ascential and buy the complete methodology for something like USD15K last I heard. And I still hear people complainÂ.ÂUSD15K for a methodology license for the entire companyÂthatÂs too much!!!ÂÂ.like I said amazingÂ.  Best Regards Â Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com   -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:owner-dwlist@datawarehousing.com] On Behalf Of Doug Little Sent: 29 June 2004 17:10 To: dwlist@datawarehousing.com Subject: Re: dwlist: Dimensional ODS  http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to   with the word "help" in the body of the message.  From: Doug Little       Chris,  The key to your question would be to specifically define what you mean by operational and analytical and then determine is those requirments can be satified by a model that provide query performance and ease of use.  I hate Inmon's et al continued redefinition of the world in order to suit their arguements. I don't know any users who can tell if they use a class 1, 2 or 3 ODS or even if they are farmers, explorers, or whatever. Why is this important?  How about the downside of having specialized data stores for particular reporting problems - ODS (both transactional and reporting), EDW, Data Marts, Opermarts, blah, blah, blah. Why do we need so many stores. Won't 1 do? What about all the resources needed to build, keep in sync and store/process the data. To me, it's like a house of cards.  IMHO reporting is reporting. Run a query, get a result and run some more. The quicker and easier it is to get the right result the better.  Cheers!       
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Neil,  "Kurt Godel proved a long time ago that no formal system is complete."  IÂd be interested in the paper or reference about this to know what he was talking about...especially since it's perfectly possible to define formal complete systems.....  You see, I spent 3 months of my life doing a proof that all mathematical based systems could be broken down to 15 (if memory serves me) logical axioms. That is, any mathematical system that was well-defined was complete and could derived from these axioms. It could be done both ways. We had to prove it from axioms up.....hhhhmmmmm......  And yes, we had to prove that relational theory was also based on mathematical theory, and that the maths was based on the axioms so that relational theory was a complete and closed expression of a system.  Isn't it amazing what some philosophy lecturers will inflict on their students...;-)  I did Epistemology and Metaphysics as well, I enjoyed the question:  'What is it possible to believe and still be rational'  much more than all the logic...  The arguments in those classes were so much more interesting!!!  And from the look of the discussion on this list of late it seems that many people believe it's possible to believe all manner of things and still be rational.. ;-)  Best Regards Â  Peter Nolan Data Warehousing Consultant and Philosophy Major( Logic and Metaphysics) ;-)    
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Brian, Thanks for the great reply.....good to see there are some people out there thinking about the business...  "One, I truly realize that business cannot be solely based on fact. That sometimes while the information is available if sought, business does not stand still. We must get comfortable with ambiguity and balance quick decision making with getting the best facts as possible."  I agree, we are never going to see 'all the facts' as the basis for 'fact based decision making'..however, I believe there is plenty of room for improvement....;-)  "My personal opinion is that the biggest challenge with IT and business is the soft-side of everything. It is not data models, hardware, and ROI. It is communication, ego, and patience."  I agree, but I would add in personality and politics......who gets the biggest budget is 'top dog'...it doesn't actually matter if the money is spent wisely.......  I am reminded of one client where we have been very successful with a previous director of marketing and we were trying to get a project with the new director of marketing.  The department claimed 'no money' for not going forward. However, they did spend USD7M on a major advertising campaign.......however, after the adds hit the airwaves there was something conspicuous missing.....the 'call to action'.....they put all these adds on but didn't say 'call us on this number 12345678'.  So, they rapidly changed the add and put up a 1800 number for people to call....and surprise, surprise, people called...but what they had forgotten this time was that the people on the companies end of the phone were not telesales people, they did customer service for existing customers....they didn't have anything to sell the people calling in and had no system to log the call and get the agent to call them back...all they could really do was say 'thank you for calling and have a nice day'.  So... then this company change the add to say 'call your local XYZ agent'....which was also a flop because PROSPECTIVE customers didn't have a local agent to call.......  The very same department decided on launching a new product. And a year later, from this directors mouth 'We screwed up on the estimates of claims and basically we have been losing money on each policy we sold. The only good news on this whole product is that we sold so little of it the loss is small.'  And lastly, another 'great idea'. In Australia, when people retire, they must move their retirement fund out of the retirement fund into an investment fund. Historically the company only retained 10% of this money. The 'great idea'? Send them a check book and a letter of the balance rather than a check for the amount. The result? Around 90% of the check books only ever had one check written, for the total amount, moving the money to somewhere else.  How could a department mess up such simple things so consistently and so badly? Well, the new director of marketing was someone I had known for longer than I had wished to, and he was something of a megalomaniac....his idea was always the best idea and so he did what he believed in.......only problem was, he'd never had quota-commission experience, he was an accountant by training.... nothing against accountants, but they are not known for their selling skills which is why they often don't move to become 'director marketing'...  Another great one I like.  I was selling to big insurance company in 1993. Again, director of marketing. The conversation went something like this...  Peter: 'Is there an agent who is way out in front of the others?'  Customer: 'Yes, we have an agent in Adelaide (city in Australia) who outsells anybody else 2 to 1. He makes over $A1M per year in commissions in his office.'  Peter: 'Is there anything specific that this agent does that most other agents don't?'  Customer: Well yes. He is really fastidious. He keeps track of everything about all his clients. Wifes name, birthday, anniversary, kids names, ages birthdays, professions, house movements. Everything. He gets his staff to send out cards like you wouldn't believe...even sends out 'thank you cards' when clients sign up for larger deals or upgrade, that sort of thing.  Peter: Do you supply this information with your systems?  Customer: Well no, we just capture what we need to manage the policy. Customer management is up to the agent.  Peter: And how does he do this?  Customer: Well last time I talked to him he was converting his card file across to a small PC system he bought. So I guess he has been doing it from a card file.  Peter: And do you think the way that this agent collects so much personal information and uses it in his dealings with his clients has got anything to do with him selling twice as much of your product as anyone else?  Customer: (thinking about it...) Well, I'd say no. Using information like that wouldn't help sell insurance policies, I'm sure.  Peter: (after having to pick myself up off the ground in surprise) Really, that's interesting. What would you say the main reason for outstanding success could be?  Customer: Well, I think he just got lucky and got a good patch.  (Note: I know a lot of people here would not know Adelaide from Timbuktoo. Let me just say no one ever got a 'good patch' in Adelaide. It is a relatively small city and not known for high rates of insurance purchases.)  When I went back to the branch the rep asked me how I went?  I told him we would not be getting a DW sale there. I also told him to start looking for a replacement account because 'these turkeys should be run out of business'. My words turned out to be more prophetic than I would have imagined...5 years later they went bankrupt in something of a major scandal in the Insurance sector in Australia.  The problem? Not enough renewal and return business and too much money spent on buying new business through advertising and discounts.....   I could go on and on about 'bad decisions I have seen'....but these are just some good ones driven from above...I've seen just as many driven from below and driven from the middle....  A good DW can record investment decisions and their results and keep that history for some years so that people don't make the same mistake again...or at least have a fighting chance.......and it can be used to guide decisions...  When I talk to directors of marketing one of the things I say is this:  "We both know that half the money you spend on marketing in wasted. That's $XX Millions dollars for you. With an XYZ system (whatever he/she wants to call it) I can tell you which half. Then, you can decide to stop spending it, or you can spend it where it does make a difference. Either way, I can help you double your marketing dollar effectiveness. Would you like to double your marketing dollar effectiveness?"  Sometimes I get thrown out. (How dare I presume to be able to do a better job than the guy across the desk?) Sometimes I get a deal. Life's like that...;-)   Best Regards Â  Peter Nolan   
    
</post>

<date>02,August,2004</date>
<post>

	 
       Hi Michael, A good topic...and one I have seen many times...   Seems I am doing more of these 'metric' DWs since the recession started than 'selling more stuff' DWs......  And we are most regularly seeing these kinds of DW projects coming up in customers who have a 'DW' and feel that it does not provide the measurements that the company is now looking for.  HereÂs my 2 cents worth...hope it's a good read... ;-)  There are three ways (at least) to go about defining metrics:  1. Engage an external consulting company to come in and charge you a considerable sum of money to come up with 200+ things that 'just have to be measured' in a business like yours.   By the way, this is not a criticism, I've sold and done projects like this. These projects can be incredibly valuable if the company is planning major organisational changes and their current set of metrics is not going to stand up to the transition. How do you manage going forward in a company when many of the measures you use will not compare 'apples' to 'apples' into the future? It's a tough transition.  All the usual suspects play in this space. (Big 6, 5, 4, 3, however many now and IBM Global Services, the ex-PwC bit.)  Personally, I thought PwC had great materials in this area.  When I was at PwC (late 90s), the suite of measures that were useful in a telco exceeded 400. As a PwC consultant, if I could not work with a telco to determine which 200 of the 400 were of value and applicable to the telco I would be doing a pretty poor job!!!   2. Look at buying a model in your business area.   I've been implementing Sybase IWS for a few years now and it has quite a 'starter kit' of business measures in a number of industry areas. With IWS the conversation is not "lets sit down and figure out what measures you should have for your business".   It is "here's a physical data model with a suite of measures that are very valuable for a business like yours. We don't think you should try to do them all at once so let's pick 50 and do them first. We store all the atomic data so you can always go back and calculate the others at a later date." Because IWS is so flexible you really can add the other measures and dimensions later.  (IWS contains some proprietary modelling techniques that make it faster and easier to add dimensions or fact tables.)  Again, personally, I think this kind of 'ready made' yet 'flexible' approach is the way to go for large organisations.  It provides the flexibility to customise along with the guidelines of what is important. (Of course, IÂd have to say that or I wouldn't be travelling around the world installing IWS!!! ;-). IÂve said on this forum a few times that I work implementing IWS and that my opinion is that IWS is the way of the future for ODS/DW. )    3. Do it yourself.   Of course option 1 and 2 come at a price.  (Though the cost of the IWS model is generally made up be reduction in days worked on the project.)   So, if you want to Âdo it yourselfÂ hereÂs my 2 cents worth.    Take a look at how the business is actually managed today and get a view (from the top) as to how the business will be managed 2-3 years out. It is often the case that senior people can net out the really important measures to a relatively small list, starting with 'profit'. They can also tell you how they plan to change the business in the next 2-3 years and they can tell you what will be important to measure during that time. But what you are looking for is Âhow is the business managed, what big decisions need to be made on a regular basis, on a non-regular basis, what measures are needed to measure, manage and monitor these big decisions?Â  IÂve written a newsletter on the ÂManagement Decision Making ProcessÂ (see my web site downloads pageÂ).  I learned this from Metaphor.  It was the ÂfilterÂ through which to pass Âpossible dataÂ. In short, if you can identify how the business will be managed into the future you can identify the data that will be needed to measure, manage and monitor that business. You canÂt help but build a valuable DW by doing this.   Example?.  I worked on an international air cargo company a while ago.  The team knew nothing about the air-cargo business when we startedÂ.but within 6 weeks we built a prototype that the CEO was pleased with, and in 6 months we had delivered what the CEO called the most successful IT project heÂd seen so far. That measurement system is on the desk of all senior managers at the company and the underlying DW is available to analysts trying to figure out why the measures are good or bad.  (By the way, we were very lucky in that the team picked up an ex-employee along the way who made a huge contribution to the projectÂ.)   If you can distil a 'short list' of 20-40 measures from the senior managers you can then start to work though, how could these be calculated? And the measures required to calculate the important measures also become measures. Pretty soon you will be up around 100 and that's good enough for a start.  From the 100 or so measures you will soon start to be able to derive the numbers that must be captured from operational systems to calculate the basic (un-asked for) measures which are then fed into the compound (asked for) measures.   Example? I worked for a client a few years ago.  The 'business requirements'. Pretty simple really.  We wanted to be at 30% gross profit not 18% gross profit. The client had noticed they were measuring how many 'successful cases' they had but were not measuring profitability until they balanced the books at the end of the year. They thought 18% was pretty good, until they found out their (smaller) competitors were regularly turning in 30-35%.  (Those who have seen my appends will know that working on a project to dramatically improve profitability in a company is much more my kind of project.)  They had an existing DW, but it did not contain the data they now needed, and they felt they needed something more sophisticated. They were going to transform the measurement and management processes of the company.  They wanted a kind of 'next generation' DW to do the things they did not have the luxury of time to figure out for themselves by trial and error.  They wanted to 'buy the learning curve' and then move forward themselves. They had some external pressures driving them and lacked enough internal people to go through the learning curve. (And, obviously, no-one internally had experience in building a profitability calculation engine since they didn't have one anywhere in the company...)  In short, they wanted to change the basic measures of the business, and from the measures change, transform the way the business was done to drive up profitability.  But they did not know what to change the measures to, nor how to transform the business processes to make such a dramatic change in profitability.  Obviously, more of the same, was not going to make the difference. Just as obviously, small changes were not going to nearly double profitability.  Also, since the business results were so closely linked to the business process 'slash and burn' was not a reasonable option. Improving business processes and growing the business were the order of the day.  So we started with the premise that we must measure profitability. We then worked through the process of figuring out what brought in money, what cost money, how to allocate costs.....we had to balance to the ledger which was a BIG problem. And in the end we came up with about 80 things to capture data about and calculations to perform. (We were implementing IWS, but IWS did not have a module for the specific business area of this customer so we had to customise IWS to contain these additional measures.)  We could then break down all the cost components of a case and the revenue components and calculate gross profit at a case level.  (And cases might run for several years before a cent of revenue is seen by the way.....)  Having done all this and rebuilt some very basic reports the results fairly leapt off the page. The areas of 'profit drain' were there for all to see.  Of course, that is only a very small part of the problem. The much bigger problem is to get the people whoÂs measures are so far down to accept the measures (they usually dispute the calculations) and then do something about it.    In this particular case we included the ability to adjust business processes for small groups of the business and measure the results in these areas before rolling them out. In fact, we built the ability to have 'continual experimentation' in improving the business processes and information used/presented in the management of a case to that many experiments could go on simultaneously over extended periods to ascertain the improvements that could be rolled back into the mainstream business processes.     This second half is, in my opinion, more important than the measures. If you can't change the business and measure the impact of the change there's not much point measuring. And if you are 'risk averse' you need to make big changes in small areas and prove the value before rolling it out across the business.  It is far easier to 'do nothing' than to make big changes to a business with no foundation/factual information that demonstrates a high probability of success.....which is what measuring provides, a pointer to the probability of success....not success itself.  (As you will have seen from my previous appends, IÂm much more interested in talking about how to make a difference to the business. ;-) )  I hope this was useful....  Best Regards Â  Peter Nolan   
    
</post>

<date>02,August,2004</date>
<post>

	 
      Hi Chris,  "This is the best post I've seen on this mail list in a year. I'm not sure why we are in the state you describe in your 3rd point, but your are right on the money. Too many DW projects take the "field of dreams" approach and amass a terabyte of data without a clear vision of how they can impact the business."  :opinion on.  Why are we in this position???  Have a look through 'the Mythical Man Month' by Frederick P. Brooks. It is over 30 years old now and it describes in great detail why we are 'in this position'.  In short, we are not 'learning' as an industry. We are prepared to make the same mistakes over and over and the business folks (who should know better) are also prepared to allow IT to make the same mistakes over and over again. Sure, we kid ourselves as we go along that we are learning, and we even have some nice cases to point to, but as a professional industry, we are doing very poorly compared to our construction cousins.  Usually, when the business folks do get ticked off enough to get rid of IT folks all they do is outsource the IT folks to EDS/CSC/IBM/HP/whoever and then hire them back and believe that 'somehow it will better with an outsourcer'..??  With data warehousing projects in particular the business is not making sure that the people doing the project know how to drive dramatic profit improvements in the business.  The business folks know there is value to be had from the data, and they ask the IT folks to help them get that value out but there is a disconnect between the two groups and often all that happens is a large amount of data is sitting around and no-one really knows what to do with it.  Knowing how to drive a business forward to make dramatic profit improvements using knowledge is THE KEY POSITION in a DW project. And there are very, very few of these people around.  WhatÂs worse is that most business folks sponsoring DW projects are completely unaware of the importance of this 'link person' and so allow the project too go ahead without one. And you can be pretty sure the local IT shop or vendor is not going to point out the lack of such skills and the implications because it is almost certain they do not have such. The vendor exception to this ÂruleÂ is Teradata which has always recruited really, really good ÂbusinessÂ IT people as well as many business people. When they are in the sales cycle, Teradata often roll more ÂbusinessÂ savvy people through an account than IÂve had hot lunches.  :opinion off.  Best Regards Â Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com   
    
</post>

<date>02,August,2004</date>
<post>

	 
      Subject: RE: dwlist: Data warehousing and MBA  Hi Tony, My thoughts are imbedded in the email    Hi all,   1) My professor told me that data warehousing will have an even bigger impact than the internet did in the years to come - meaning it will completely change the world as we know of it. I believed him when he said it, and I would like to believe that now. What do you guys think?   >>> I like your professors optimism but I donÂt see this happening any time soon.  >>>When Âthe webÂ happened and brio launched the Âweb warehouseÂ with the slogan Âwhere the warehouse meets the webÂ (circa 1996) I was one person who confidently predicted this will bring together the two most powerful forces in IT and drive a revolution in Sales and Marketing, Business Management and Business Development.  >>>However, just like we did with relational databases in the late 80s and early 90s (as described by Ralph so eloquently in the first edition of his book) we have managed to snatch defeat from the jaws of victory. Instead of making the right data readily available to the people who really need it with tools they can really use to do what could make a really big difference to the business we gave everyone a pretty dumb browser interface and we gave lots of people access to data that they have barely any earthly use for other than to fill up their 8 hour working day fiddling around with it. Oh, but these dumb web interfaces have nice pretty charts and buttons and things and that makes all the differenceÂ..hhhmmmmm.  >>> The definition of a data warehouse included Âto support the management decision making processÂ and especially in these days of post latest recession downsizing the number of managers to ÂstaffÂ is smaller than it has ever been. As far as I am aware no-one of any reputation has expanded the definition of a DW to include Âto provide reports to anyone who wants one regardless of whether it will make any difference to the business.Â But that is what the vendors like to sell because it makes the most money and plenty of businesses have bought it.  >>> Having said that, I still believe the use and the impact of the DW is still in itÂs infancy. I also believe the factors holding back the use of information inside organisations for the organisation benefit are political and not technical. Middle managers really donÂt want senior managers to see the real numbers. And in many countries the senior managers donÂt want to see the real numbers either so they have Âplausible deniabilityÂ on their side. And when some analyst comes up with a great idea and it makes millions of dollars it is pretty common for his/her colleagues to then Âmake life difficultÂ for the Âstar performerÂ.    2) I read an interview done by some online magazine with Google's Larry Page. In it, Larry shares his vision for his search engine being able to answer any question in the world. I couldn't stop to wonder what the future of data warehousing would be. Isn't the ultimate purpose of data warehousing also similar - to answer how to do anything in the world most effectively? If so, maybe we can see some merging of technologies in search and data warehousing technologies? Am I completely off base?  >>> No. The purpose of the DW is defined to be Âto support the management decision making processÂ. Sure, you might want to expand on that definition for your particular DW. However, in any organisation, there is only a very limited set of decisions to be made which drives only a very small number of ÂquestionsÂ compared to the set of Âall questions that could be askedÂ. If a DW project concentrates on Âthe set if possible questions that will make a major difference to the organisationÂ and collects the data for that rather than Âany possible questionÂ and collects the data for that, the project is far more likely to be successful.  >> Feel free to read about this here: http://www.intelligententerprise.com/010507/webhouse1_1.shtml  >> The dimensional model is a great way to highly focus the DW effort since the ÂfactsÂ that can be used to answer a question must be in a fact table. In the early days we could put a large amount of the transactions of an organisation and put them into fact tables and this gave us a great resource to focus our questions around.    3) I've been in the IT industry for the past 5 years, and I feel like in order to get to the next level, I really need to get into the business side of things. And I thought one of the best ways to do it is to go get an MBA from one of the top schools in the states. However, I also want to continue doing data warehousing, and try to be a data warehouse expert and this makes me think that an expensive MBA may not be all that helpful. But I am not sure which path to choose. I guess knowing where data warehousing will be in the next 10-20 years from now, and what big role I can play in data warehousing will be helpful.   >>> No-one knows where data warehousing will be in 10-20 years. One thing is for sure. The world will look more different in 20 years than it does now from 20 years ago. And that is Âvery differentÂ. I would not make any choice or decision on what to do in IT with a more than 2 year time horizon at the moment. Microsoft and Sun have Âkissed and made upÂ who knows whatÂs going to happen next!!!???  >>> My personal opinion is that MBAs are not worth that much. Indeed, I believe most tertiary education pales by comparison to experience in the Âreal worldÂ. Sure, you have to have the piece of paper to Âget in the doorÂ. But many companies nowadays want Âsecretaries with degreesÂ.. (Why??) I have always believed that if you put your hand up to take on the most difficult tasks at work and can make them successful you are likely to learn more. The trick being get 10 years experience, not 1 years experience 10 times over.  >>> Mind you, being highly successful in the roles you perform does not mean you will get paid more or be more ÂsuccessfulÂ. In many cases the Âmost successfulÂ person is Âfirst against the wall after the revolutionÂ. Just remember, life is not fair, and I am very pleased that it is notÂ ;-)  Thanks!  Tony Lew  Best Regards Â  Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com   
    
</post>

<date>02,August,2004</date>
<post>

	 
       Hi Claire, I know Jim and yes, he does know the product very well.    The biggest problem in describing what Meta5 can do to someone who does not know Meta5 is that Meta5 is so sophisticated and can do so much, how do you describe it in terms someone can understand? ItÂs very hard. I ran sales cycles at more than 20 large companies in the early 90s and explaining what DIS (in those days) did was the hardest part of the sales cycle!!!  And very few people could see that they needed something like DIS. Meta5 is still my Âall timeÂ favourite piece of software in terms of being able to dramatically improve the profitability of an organisation.    Ralph can probably contribute some of the earlier Âwar storiesÂ of trying to explain to people what DIS did. It must have been an amazing conversation in the mid to late 80s!!!  The short Âsales pitchÂ is that Meta5, well implemented, will dramatically increase the profitability of any large sales based organisation.  ItÂs just that not many people believe that up frontÂ.so you go into a sales cycle prospects can understandÂ.  What Jim is talking about is some new features of Meta5 that allow you to integrate separate disparate BI environments.    You want data moved between Excel, Business Objects and Brio, Meta5 can do it.  You want data from XL sheets, Brio, BO, web pages, whatever, integrated into a single new report and emailed to people on a regular (or even exception) basis, Meta5 can do it.  You want data brought from all different types of databases, files etc and put onto one report. Meta5 can do it.   Jim has called this ÂBIIÂ Business Intelligence Integration because, like it or not, we seem to have now developed Âlegacy BI applicationsÂ that donÂt talk to each other.  (Will we in IT ever develop anything that does not become ÂlegacyÂ and impossible to integrate with anything else??? Probably not!!!) Also, there is still a lot of data that in not in the data warehouseÂ..particularly data on spreadsheetsÂ.  Jim and Meta5 are focussing on talking about BII because it is currently a significant issue in many large customers and Meta5 is unique in itÂs ability to perform BII. After all, the BI vendors have little interest in integrating their products with their competitors!!  The Âad-hocÂ part refers to how Meta5 is often used. That is, someone walks up to a PC with a vague idea in mind and develops a small (or large) analytical application to test the validity of the ideaÂ.no planning, no documentation, just some tools on a desktop to test an idea. The data does not need to be in a DWÂanything electronic will do, Meta5 can join together data from just about any electronic source on the planet.  If the idea is good, it might move forward, if it proves that the numbers donÂt support the idea, it dies. All will almost no effort on the part of the business person to test the idea.  For those who have seen DataStage the Meta5 interface is very similar but much better than DataStage. I would be very surprised if the developers of DataStage had not Âgone to schoolÂ on Meta5. Indeed version 7 of DataStage has just introduced the ability to copy an icon between jobs, something that was available in DIS in 1985 I believe!!!    Even today, extremely few IT people understand what the business could really do with their data if they had a tool like Meta5 available.   My previous append focused on another specific area of incredible strength of Meta5.   That is. Business users (and I mean the MBAs or Business Analysts) do not need to communicate what it is that they want to an IT person in order to get it.     The value of Meta5 is obvious to business people and can be summed up in one sentence.   ÂReduce the dependence of developing strategically important information and knowledge on the IT shop.Â  (No wonder itÂs not that popular with IT peopleÂ. ;-) ).  Just think about what this truly means, just for a second.   What if it was possible to give a business person a tool that was so powerful (yet easy to use) that they didnÂt need to talk to the IT shop to develop a one off or systematised analysis/reporting application???  They could go Âdata miningÂ around in their data as they wished. Sometimes they will come up with a lump of coal, sometimes with a gold nugget.  But the very fact they can do it for themselves quickly, easily, painlessly without even having to talk to someone else encourages them to keep going.  Just this simple fact means business users using Meta5 are going to be way in front of competitors because their cycle time for decision support is reduced.   For example, if a business person has a really Âfar outÂ idea they donÂt take the chance on Âlooking sillyÂ by getting someone to crunch the numbers to see if the idea is supported by what is happening in the real world.  They can crunch the numbers for themselves and see if it flies or not.   This is incredibly important. It means some of the most Âfar outÂ ideas do not die at the first hurdle of Âother peoples perceptionsÂ of the wild duck that came up with the idea.    With a tool like meta5 and good people it is pretty common to see the investment in the entire system paid for 4-5 times over each year. Payback periods of 2-3 months is common. IÂve heard of 2 weeks to pay back a USD500K DIS install. Our best effort was a single decision that brought in 15 times the cost of the system annually!!!   My first DIS customer got their money back for the system during the Âtrial periodÂ.  In fact they made the 2 biggest decisions the company had EVER made during the Âtrial periodÂ based on information developed from the prototype DW.  This is how many DIS customers operated. Smart people mining data looking for the Ânext big thingÂ.   The technology is unbelievable and still so far ahead of the curve itÂs not funny, but great technology does not necessarily translate into great salesÂ..   Best Regards Â  Peter Nolan Data Warehousing Consultant Mobile: +353 879 581 732 Homepage: http://www.peternolan.com   -----Original Message----- From: owner-dwlist@datawarehousing.com [mailto:owner-dwlist@datawarehousing.com] On Behalf Of Claire McFarlen Sent: 08 May 2004 17:00 To: dwlist@datawarehousing.com Subject: Re: dwlist: Rule based Architecture & ETL  http://www.DataWarehousing.com is sponsored by DataMirror, a leading provider of real-time data integration and resiliency solutions. Please visit our sponsor today at http://www.datamirror.com to access data warehousing white papers and best practices.  For help with list commands, send a message to   with the word "help" in the body of the message.  From: "Claire McFarlen"     Hi Peter, I checked out Meta5 and found a corporate statement posted by Jim Kanzler, CEO and president of Meta5, in which he says something a bit different from what you describe.  Kanzler describes the Meta5 product as a tool to integrate "ad hoc data" with existing corporate BI data.  His definition of  "ad hoc data" is "data that's too small or out of place for your corporate systems or data warehouse, data from departmental databases, spreadsheets, ASCII files and from the web".  He says that end users want to create their own "applications" by combining this "ad hoc data" with the BI data produced by IT, to get a more comprehensive understanding of their own area of inquiry, and that since it's impossible for IT to deliver every piece of information a user might want in a timely manner, the Meta5 tool will "automate the cutting and pasting" of "ad hoc data" into other data supplied by IT from corporate systems and DW.  I've not encountered Kanzler's definition of ad hoc data before, although it's an interesting one.  In my experience, ad hoc data refers to data that is produced by querying and re-querying corporate data with various olap/data mining/BI tools at any point in time, allowing for repeatable queies that produce different results over time, owing to changes from corrections, updates, and additions.  Kanzler doesn't, unfortunately, define what is an end user "application" - must be equally interesting.  I found his statement on MacReport.net, its an audio file:  http://www.macreport.net/ceo_int/ceoint_pri.asp?symbol=META5  Have they significantly expanded their product since this statement was issued by Kanzler last year?  It's the most recent statement according to their own website.  Or is it possible he does not understand the full scope of his own product?  Or is there another company also called Meta5 that is in the same market with the product you are describing?   Claire McFarlen Data Warehouse Consultant Clay New Media     ----- Original Message -----  From: "Peter Nolan"   To:   Sent: Friday, May 07, 2004 7:13 AM Subject: RE: dwlist: Rule based Architecture & ETL   > http://www.DataWarehousing.com is sponsored by DataMirror, a leading > provider of real-time data integration and resiliency solutions. > Please visit our sponsor today at http://www.datamirror.com > to access data warehousing white papers and best practices. > > For help with list commands, send a message > to   with the > word "help" in the body of the message. > > From: "Peter Nolan"   > > > Hi Neil, > > "I can't believe that in 2004, all of out DW processes, ETL, BI, etc., > still hook up directly to the physical models of databases. It's not > only a huge maintenance cost, it is too limiting." > > You say a lot of interesting and challenging things in this list, and I > think this is one of the best comments you have made for a while. I too > cannot believe we have not yet somehow abstracted ourselves from the > database when we are writing our applications. In particular, I can't > believe we have not given over the development of so-called BI > applications to the business user. > > I feel we have taken something of a step backwards over the last 10 > years in 'decision support' for the 'big' decisions that hugely affect > companies in favour of trying to sell large numbers of over priced seats > of so-called decision support software to people who, if we really face > it, are not in a position to make 'big' decisions that will change the > course of a company. > > Meta5 is very, very close to completely abstracting the data model such > that the business user.  Meta5 allows us to ecapsulate the query and > then the business user (who can actually develop their own applications > in meta5) can deal with the data as just a data stream coming from > somewhere. And that same underlying format of the data stream is common > to all the tools. > > There are also a variety of tools built into Meta5 that communicate to > the database via a workstation tools data dictionary that pretty much > completely hides the underlying model. (I find it hard to believe BO is > winning court cases saying they invented the semantic layer...) > > Meta5 then allows the construction of applications processing the data > streams to perform whatever analysis and highlighting required > situations that might require attention. > > Most importantly, Meta5 allows business users to access and manipulate > complex information with very close to zero knowledge of underlying > technology (your accelerator analogy) such that they never actually have > to communicate their needs to an IT person. > > We all know and agree that the very act of the business person > communicating what they want to the IT developer is where at least 80% > (if not more) of the development problem is. > > To take your car analogy a little further. > > I've been in a non-english speaking country for the last 15 months > (Saudi Arabia). I know how to drive a car and if I drove a car here I > would be able to get myself around. However driving here is so dangerous > that I choose to take cabs, and often the cab driver speaks no English > at all and cannot read the latin based alphabet. > > A lot of the mixups I've had getting around are because I've had to > communicate to the cab driver where I want to go, and sometimes I didn't > really know how to get where I wanted to go. I just had an address in > English and I've had to describe what the buildings near where I want to > go look like in hand signals and hope we can find our way. I've had > plenty of trips where I've had to call someone who spoke the local > language on my mobile and get the cab driver to talk to the local to > give directions to the cab driver. > > This is somewhat similar to what we are still doing in BI. Business > people trying to describe where it is they want to get to to people who > don't speak the same language or have the same background. When are we > going to make popular tools that allow the business users to do their > own driving? > > And one thing we will have to achieve on the way is very close to > complete disconnection from the database model to the business view of > the world. > > > (Footnote: Just for everyone else, I am going to start talking about > Meta5 as a current product rather than the old DIS from Metaphor. Now I > have found it is alive and well and had a chance to try out the latest > version on my laptop I think I should talk about it as a current > product, you can go out and buy it, and that's current enough for me.. > ;-) ) > > Best Regards > > Peter Nolan > >  
    
</post>


</Blog>