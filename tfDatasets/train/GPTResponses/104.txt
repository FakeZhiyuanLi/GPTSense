The Age of Imperialism can be said to have ended around the beginning of World War I in 1914, when many Western powers began to focus on the war effort and their colonial empires started to dissolve slowly thereafter. Additionally, anti-colonial nationalist movements across the world began to rise, leading to the decline of imperialism in the subsequent decades.